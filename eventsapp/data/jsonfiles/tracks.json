{
	"0.0.1": [{
		"00": {
			"title": "Registration",
			"description": "Register yourselves and get your goodie bag. Have a great day!",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"01": {
			"title": "Effectively Debugging Deep Neural Networks",
			"description": "\\n\\n#### **Description:**\\n\\nDeep learning is expensive. Not only is there a steep (human) learning curve,\\nthere is also an immense cost in designing and training a deep neural network.\\nIn typical R&D settings, it is very common for a deep network to take days to\\ntrain. To make things even more tough, there are no guarantees of convergence.\\nIt is not uncommon to find that a network has learnt nothing even after hours\\nor even days of training. And it is likely that we as practitioners, too,\\nmight not learn much from the experience. The worst possible way to deal with\\nan untrainable network is to leave it alone (apart from a few minor tweaks\\nlike changing the learning rate or picking a different training subset of the\\ndata) and let it run for another few hours or days.\\n\\nPython is known best to be a language that allows you to do rapid prototyping.\\nBut even this feature is at its least impressive when it comes to deep\\nlearning (understandably so, since Python is just the top layer in most deep\\nlearning frameworks). Nevertheless, there are many techniques one can employ\\nto help improve feedback from the network, and even to fail fast, thereby\\nsaving precious time.\\n\\nWhile no algorithm or technique can guarantee whether a network will learn\\nanything to a specified degree, there are many practices we can use to be\\nrelatively more confident about the performance of the network, as against\\nbeing totally in the dark. One should be able to say with some confidence,\\nthings of this sort:\\n\\n> \"The loss should have dropped below X by now.\"\\n\\n>\\n\\n> \"It should have learnt to classify at least the second category from the\\nrest.\"\\n\\n>\\n\\n> \"It should clearly not be taking so long to converge.\"\\n\\nThis is an advanced workshop intended to make users comfortable with debugging\\ndeep networks.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Basics of neural networks: The audiences should know what the different hyperparameters of neural networks are, especially learning rate, gradient optimizers, regularization methods etc. We will be learning how to pick the correct combination of these for a specific problem.\\n  * Entry-level experience with keras\\n  * Basics of either one of tensorflow of theano\\n  * A laptop with a at least a quad-core processor (you should see four cores when you open the Task Manager or htop) and and at least 4GB memory.\\n\\n\\n\\n#### **Content URLs:**\\n\\nIn progress.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am a data scientist based in New Delhi. I currently work as the Practice\\nLead, Data Science at Juxt Smartmandate Analytical Solutions Pvt Ltd. I am an\\nactive member of the Python community. I've spoken at various conferences\\nabout my FOSS work. My research interests are in signal processing and machine\\nlearning. In my spare time I like to dabble with applications of machine\\nlearning in personal productivity.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n[![](https://image.flaticon.com/icons/png/128/12/12195.png)](https://jaidevd.github.io)\\n[![](https://cdn1.iconfinder.com/data/icons/logotypes/32/twitter-128.png)](https://twitter.com/jaidevd)\\n[![](https://cdn0.iconfinder.com/data/icons/octicons/1024/mark-\\ngithub-128.png)](https://github.com/jaidevd)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/effectively-debugging-deep-neural-networks~e3Y4b/",
			"speaker": {
				"name": "Jaidev Deshpande",
				"info": "",
				"photo": ""
			}
		},
		"02": {
			"title": "Concurrency in Python 3.0 - Writing concurrent and parallel programs in Python",
			"description": "\\n\\n#### **Description:**\\n\\nThis workshop is influenced and partly derived from my PyDelhi workshop\\n[\"Concurrency in the Python 3.0 world\"](https://cfp.pydelhi.org/pydelhi-\\nconference-2017/proposals/concurrency-in-the-python-30-world-oh-my~aMj3b/\\n\"Concurrency in the Python 3.0 world\") given this year.\\n\\nFrom my experience, most Python developers aren't still aware of the\\nfundamental principles of concurrent programming, parallel computing and how\\nto identify problems that yield well to data parallelilsm.\\n\\nWhile the PyDelhi workshop focussed on introducing different types of\\nconcurrent programming techniques available in Python, this workshop wil be\\nfocussed more on concurrency using multiple processes - via the\\nmultiprocessing library and concurrent futures modules.\\n\\nThe focus is to enable the attendees to pick up the skills to write programs\\nthat scale to more than 1 CPU core.\\n\\nWe will start off with an introduction to concurency and parallelism plus why\\nthe GIL behaves the way it does with an example.\\n\\n  1. What is Concurrency - 5 min \\n  2. Concurrency vs Parellelism - 5 min \\n  3. The GIL weakness - Multithreading vs Multiprocessing - 10 min\\n    1. Prime number example with multiple threads & multiple processes\\n    2. Illustrating how GIL forces computing to 1 core\\n\\nNext will be an introduction to Multiprocessing & Concurrent futures with some\\nsimple examples.\\n\\n  1. Quick introduction to multiprocessing - 10 min\\n  2. Concurrent futures - Introduction (10 min)\\n    1. ThreadPool vs ProcessPool executors\\n\\nNow time for example problems which can be scaled using data parallel\\ntechnique.\\n\\n  1. \"Data Parallel\" problems - 5 min \\n  2. Matrix Multiplication - 20 min\\n    1. Serial\\n    2. Parallel version using Multiprocessing\\n  3. Mandelbrot Fractals - 20 min \\n    1. Serial\\n    2. Parallel version using Multiprocessing\\n  4. A simple web crawler - 20 min\\n    1. Serial\\n    2. Concurrent version using Multiprocessing\\n    3. Concurrent version using concurrent futures\\n\\n[Break] - 5 min\\n\\nNext I will demonstrate a Maze solver in Python and then show how to speed it\\nup using parallel processing. (Note that this is experimental and maybe be\\nreplaced with something else in the actual talk !)\\n\\n  1. Maze solver in Python (30 min)\\n    1. Linear\\n    2. Speed up using Multiprocessing\\n\\nNext the aspect of timing and measuring performance of your\\nparallel/concurrent code.\\n\\n(30 mins)\\n\\n  1. Why wall clock time is not all that matters\\n  2. Using simple \"time\" command\\n  3. Using \"timeit\" module\\n  4. Debugging concurrent code\\n\\n(If time allows)\\n\\n  1. Generators & concurrent futures - Some advanced examples - 15 min\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  1. Python programming fundamentals - Knowledge of generators is useful indeed.\\n  2. Some awareness of Python GIL.\\n  3. Some awareness of concurrent computing.\\n  4. The code & discussions will be based on Python 3.x - the latest at that time.\\n\\nThis workshop is _NOT_ for those who are just starting out as Python\\nprogrammers.\\n\\n\\n\\n#### **Content URLs:**\\n\\nTBD\\n\\nIt will be somewhat based on the content at\\n<https://github.com/pythonhacker/pydelhi2017concurrency> . Some examples such\\nas the Mandelbrot one will be same.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nAnand has been a long time advocate and community leader of the Python\\nprogramming language in India and Bangalore.\\n\\nAnand founded the BangPypers community in Feb 2005 as the result of a meeting\\nof Bangalore Pythonistas. Discussions in this community went on to build other\\ncommunities and laid the foundation of PyCon India and similar conferences.\\n\\nHe has 17+ years of software development experience having worked in a variety\\nof technical roles in a number of software companies. He is currently working\\nas Senior Architect at Yegii Inc., a startup from MIT, where he spends his\\ntime writing web crawlers to perform focussed and deep crawls for structured\\nand unstructured data and to develop the next generation AI search engine for\\nknowledge discovery.\\n\\nHis interests are high performance computing architectures, large-scale web\\ncrawling, information extraction & security.\\n\\nAnand is also the author of a book discussing [Python and Software\\nArchitecture](http://www.blog.pythonlibrary.org/2017/06/22/book-review-\\nsoftware-architecture-with-python/) for Packt Publishing, published in April\\n2017.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  1. <http://twitter.com/skeptichacker>\\n  2. [https://github.com/pythonhacker](http://%20https://github.com/pythonhacker)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/concurrency-in-python-30-writing-concurrent-and-parallel-programs-in-python~bm7Ee/",
			"speaker": {
				"name": "Anand B Pillai",
				"info": "",
				"photo": ""
			}
		},
		"03": {
			"title": "Computer aided algebra system (CAS) for different programming languages using  SymEngine and SymPy",
			"description": "\\n\\n#### **Description:**\\n\\n**What do a mathematical students or normal people need to perform symbolic\\nmanipulation for the resolution of common problems?**\\n\\nA simple and interactive program that can do manipulation of mathematical\\nexpressions in symbolic form effectively.\\n\\n**SymPy** is a pure Python library for symbolic mathematics that can be used\\nas an interactive command line, using IPython and Jupyter notebook. It aims to\\nbecome a full-featured computer algebra system (CAS) while keeping the code as\\nsimple as possible in order to be comprehensible and easily extensible. SymPy\\nis written entirely in Python and does not require any external libraries.\\n\\nThis tutorial is intended to cover the basics as well as touch on more\\nadvanced topics and new features that are added recent years. We will start by\\nshowing how to install and configure this Python module. Then we will proceed\\nto the basics of constructing and manipulating mathematical expressions in\\nSymPy. We will also discuss the most common issues and differences from other\\ncomputer algebra systems, and how to deal with them. In the remaining part of\\nthis tutorial we will show how to solve mathematical problems with SymPy.\\n\\nThis knowledge should be enough for attendees to start using SymPy for solving\\nmathematical problems and hacking SymPy's internals (though hacking core\\nmodules may require additional expertise).\\n\\n**SymEngine** is a standalone fast C++ symbolic manipulation library. Optional\\nthin wrappers allow usage of the library from other languages (Python, Ruby,\\nJulia, Haskell).\\n\\nThe workshop will also include a hands-on introduction to SymEngine in Python\\nfor the advantages of speed while using SymPy. This section would focus\\nheavily on SymEngine's Python wrapper called SymEngine.py, and the various\\nmethodologies employed by it, the use of Cython, an account of the modules\\ncurrently supporting the use of SymEngine, the subsequent impact on\\nperformance and the major projects using SymEngine. In addition to the above,\\nthere will also be a light introduction towards installation and usage of\\nSymEngine library in Ruby, Haskell and Julia, through their respective\\nwrappers.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nWe expect attendees of this tutorial to have basic knowledge of Python, C++,\\nRuby, Julia and mathematics. However, many more advanced topics for SymPy will\\nbe explained during presentation and basic examples for SymEngine wrappers. No\\nprior knowledge of SymPy or other Python libraries is required, although it is\\nsuggested that attendees be familiar with the IPython notebook.\\n\\nWe recommend that the attendees install the Anaconda Python distribution which\\nincludes SymPy, NumPy, and IPython. Once Anaconda is installed simply type the\\nfollowing in a terminal to install the necessary packages:\\n\\n`$ conda install numpy ipython-notebook sympy`\\n\\nOther alternative installation instructions can be found here:\\nhttp://docs.sympy.org/dev/install.html\\n\\nSymEngine and its Python wrapper can be installed directly through:\\n\\n`$ conda install -c conda-forge python-symengine`\\n\\nOther alternative installation instructions can be found at:\\n\\n  * <https://github.com/symengine/symengine/wiki/Building-SymEngine>\\n  * <https://github.com/symengine/symengine.py/>\\n  * <https://github.com/symengine/symengine.rb/>\\n  * <https://github.com/symengine/symengine.jl/>\\n  * <https://github.com/symengine/symengine.hs/>\\n\\n\\n\\n#### **Content URLs:**\\n\\nSymPy team has developed and delivered many talks and tutorials at SciPy and\\nother conferences.\\n\\nThe website for the workshop at PyCon India 2017 is\\n[here](https://shekharrajak.github.io/PyCon-SymPy-SymEngine/) (You can find\\nthe introduction slides, the sphinx tutorial, and The exercises in form of\\nIPython notebooks in the website navbar).\\n\\nNote: that the notebooks are hosted statically, you can download from the\\n[repo](https://github.com/Shekharrajak/PyCon-SymPy-SymEngine) and run locally\\nto have an interactive session.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nSymPy India developers will be conducting the workshop:\\n\\n  * [Amit Kumar](https://github.com/aktech), Core Developer & GSoC-cer at SymPy\\n  * [Shekhar Prasad Rajak](https://github.com/Shekharrajak) : NIT Warangal | Core Developer at SymPy GSoC 2016 | Solvers, Sets   \\n\\n  * [Shikhar Jaiswal](https://github.com/ShikharJ) : IIT Patna | Student Developer at SymPy GSoC 2017 | SymPy - SymEngine Integration and Python Wrappers\\n\\n\\n\\n#### **Speaker Links:**\\n\\nWorkshop resource website: <https://shekharrajak.github.io/PyCon-SymPy-\\nSymEngine/>\\n\\nResource repository: <https://github.com/Shekharrajak/PyCon-SymPy-SymEngine>\\n\\nSymPy website: <http://www.sympy.org/en/index.html>\\n\\nSymPy live: <http://live.sympy.org/>\\n\\nGitHub repository: <https://github.com/sympy/sympy> ,\\n<https://github.com/symengine/symengine>\\n\\n**Links to previous tutorials/talks**\\n\\n  * SymPy Tutorial | SciPy 2014: <https://www.youtube.com/watch?v=Lgp442bibDM>\\n  * SymPy Tutorial | SciPy 2013: <https://www.youtube.com/watch?v=dAgShwIx72c>\\n  * PyDy Tutorial | SciPy 2015: <https://www.youtube.com/watch?v=mdo2NYtA-xY>\\n  * SymEngine Tutorial | PyCon India 2015: <https://www.youtube.com/watch?v=DWU2tKlacZE>\\n  * SymEngine Tutorial | SciPy 2016: <https://www.youtube.com/watch?v=03rBe2RdMt4>\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/computer-aided-algebra-system-cas-for-different-programming-languages-using-symengine-and-sympy~eXnob/",
			"speaker": {
				"name": "Shekhar Prasad Rajak",
				"info": "",
				"photo": ""
			}
		},
		"04": {
			"title": "Dev Sprints",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"05": {
			"title": "Python for Data Analysis",
			"description": "\\n\\n#### **Description:**\\n\\nTypically it takes 60 to 80% of the time to collect required data, cleanse it\\nand analyse in any data science project. It is very essential for one to be\\nfamiliar with various tools/libraries available in python for doing data\\nanalysis and understanding the data. This hands on workshop's objective is to\\nprovide overview of the libraries and how to use them for various activities\\nperformed during the data analysis\\n\\nFollowing will be covered as part of this session\\n\\n  * How does data analysis fit in the life cycle of data science project\\n  * Dealing with numpy arrays\\n  * Reading data using various formats, dealing with missing values\\n  * Using pandas plot features to visualize and understand the data\\n  * Analyzing one of the open source data set\\n\\nBy the end of the session, audience will have very good understanding of how\\nto apply numpy, pandas to analyze, understand and prepare data set required\\nfor starting machine learning\\n\\n\\n\\n#### **Prerequisites:**\\n\\nHands on exposure with basic python programming language\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://github.com/sdonapar/python_training\\n\\nhttps://github.com/sdonapar/data_analysis_made_easy\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am a mechanical engineering graduate with 25+ years of experience in\\nmanufacturing and financial services domains, I have started my career as\\ndesign engineer in hydraulic turbine manufacturing company. After spending 5\\nyears, I have stated my IT journey at Aspect Development/i2 Technology. I have\\nworked primarily on data scrubbing, modelling, analysis and data migration\\nprojects for supply chain management. I then joined technology services side\\nof Fidelity, financial services company. I have been using python for last 5\\nyears for automation, data analysis, web development, etc. I am very excited\\nabout the endless opportunities that arise in day today work and application\\nof python for solving/automating the same. I am very passionate about teaching\\npython to engineering students thru pythonexpress program. I conduct regular\\ntraining sessions for data analys ( numpy, pandas and matplotlib).\\n\\n\\n\\n#### **Speaker Links:**\\n\\ngithub link - https://github.com/sdonapar\\n\\nlinkedin profile - https://www.linkedin.com/in/sasidonaparthi\\n\\ntwitter handle - **@sdonapar**\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/python-for-data-analysis~eVJBe/",
			"speaker": {
				"name": "Sasidhar Donaparthi",
				"info": "",
				"photo": ""
			}
		},
		"06": {
			"title": "Lunch",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"07": {
			"title": "Making Machine Learning Fruitful and Fun using Orange",
			"description": "#### **Description:**\\n\\nIn this workshop we will visually uncover the various aspects of an Analytics\\nPipeline using [**Orange 3**](https://orange.biolab.si/), a Python based open\\nsource interactive data analysis, machine learning and data visualization\\nworkbench. Its simple \"drag-and-drop\" based workflow design interface makes it\\nideal for novices, and its modular design, extensibility and python\\nintegration makes it powerful for advanced data science.\\n\\nThe workshop will begin with the building of basic analytics pipeline using\\nbuilt-in Orange widgets, which will further evolve into complex analytics\\npipeline covering advanced topics like - In-database analytics, Using external\\nML toolkit, Integration with R, Exporting developed models etc. For these\\nadvanced topics the audience will be made familiar with the GUI and\\ncomputational concepts involved in the development of add-on (custom-built)\\nwidgets for Orange.\\n\\nHands-on experience of the various aspects of Data Analytics Pipeline will be\\nprovided in this workshop:\\n\\n  * Data Access (files & external data sources)\\n  * Data Exploration\\n  * Data Transformation/Filtering\\n  * Model development using supervised/unsupervised machine learning algorithms (in-built, scikit-learn, in-database, nltk, R-integration)\\n  * Basic and advanced Visualization (in-built, matplotlib)\\n  * Exporting developed model (PMML, PFA)\\n  * Champion/Challenger model experiments\\n\\nReal life analytic use cases (Sentiment Analysis, IoT, Finance) will be\\nselected for the workshop.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nNone for building basic analytics pipeline.\\n\\nBasic Python Programming (development of simple functions and classes) for\\nwidget development section.\\n\\nDownload [Orange 3](https://orange.biolab.si/download/).\\n\\n\\n\\n#### **Content URLs:**\\n\\nMy [Youtube video](https://www.youtube.com/watch?v=ByGfO6svDAM) shows the\\nexecution of an advanced in-database Decision Tree Model using Orange.\\n\\nThe developed [orange3 add-on\\nrepository](https://bitbucket.org/ankitmahato/orange3-saral) used to provide\\nwidgets for the analytics pipeline mentioned in the above video.\\n\\nPlease note that the above video and repository demonstrate an advanced Orange\\n3 capability which will be covered in the workshop.\\n\\nThe complete agenda and content will be provided soon.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nAnkit is a Product Manager with 3+ years of industrial experience in machine\\nlearning, quantitative modelling, data analytics and visualization. Over the\\nyears, he has developed an expertise in handling the entire data analytics\\npipeline comprising \u2013 ingestion, exploration, transformation, modeling and\\ndeployment. He is a polyglot programmer with an extensive knowledge of\\nalgorithms, statistics and parallel programming. He has shipped multiple\\nreleases of [DB LytixTM](http://www.fuzzylogix.com/products/db-lytix/), a\\ncomprehensive library of over 800 mathematical and statistical functions used\\nwidely in data mining, machine learning and analytics applications, including\\n\u201cbig data analytics\u201d.\\n\\nA die hard Pythonista, Ankit is an open source contributor and a former\\n[Google Summer of Code 2013 scholar (under Python Software\\nFoundation)](https://www.google-\\nmelange.com/archive/gsoc/2013/orgs/python/projects/ankitmahato.html).\\nCurrently, he is contributing to the following open source projects:\\n\\n  * [opendatagroup/hadrian](https://github.com/opendatagroup/hadrian) \\- Implementations of the Portable Format for Analytics (PFA)\\n  * [Fuzzy-Logix/AdapteR](https://github.com/Fuzzy-Logix/AdapteR) \\- Advanced analytics package that enables R users to perform in-database analytics\\n\\nAn IIT Kanpur alumnus, Ankit is also an active researcher with publications in\\ninternational journal and conferences. He is actively working in the domain of\\nIoT Analytics and recently presented his work - \u201cIn-database Analytics in the\\nAge of Smart Meters\u201d in the 5th IIMA International Conference on Advanced Data\\nAnalysis, Business Analytics and Intelligence, 2017.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nLinkedIn - [Link](https://www.linkedin.com/in/ankitmahato)\\n\\nYoutube channel -\\n[Link](https://www.youtube.com/channel/UCZN2KnRDsfNpz5DQP5wDcZw?view_as=subscriber)\\n\\nBlog - [Link](https://ankitmahato.blogspot.in/)\\n\\nGithub - [Link](https://github.com/animator)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/making-machine-learning-fruitful-and-fun-using-orange~egMjb/",
			"speaker": {
				"name": "Ankit Mahato",
				"info": "",
				"photo": ""
			}
		},
		"08": {
			"title": "Creating Captive Portal with Tornado and Raspberry Pi",
			"description": "\\n\\n#### **Description:**\\n\\n# Aim of the workshop\\n\\n  * The aim of the workshop is to give insights about on how to create Captive Portal using Tornado and Raspberry Pi. This workshop will cover the following aspects. \\n  * Creating open hotspot using Python and HostAPD\\n  * Configuring HostAPD on Raspberry Pi\\n  * DHCP Configuration and Management \\n  * Creating Basic App using tornado\\n  * System Process and Runnables\\n  * Hands on Raspberry Pi\\n\\n# What is a Captive Portal ?\\n\\n  * A captive portal is a Web page that the user of a public-access network is obliged to view and interact with before access is granted. Captive portals are typically used by business centers, airports, hotel lobbies, coffee shops, and other venues that offer free Wi-Fi hot spots for Internet users.\\n\\n## Advantages of Captive Portal\\n\\nCaptive Portals allow for the separation and segregation of guest traffic.\\nThis has tons of security benefits including keeping un-trusted users away\\nfrom confidential resources through network access control policies.\\n\\n  * These portals provide data accounting based on time, date and user. This is a standard feature in guest access. Future access to logs will facilitate administrators to find out certain users and their actions in a corporate network.\\n  * A landing page will serve as a means of identifying your brand as well as a way to boost your marketing message. Companies can take advantage of the virtually limitless potential that captive portals possess to raise brand awareness by utilizing its less obvious abilities.\\n  * Providing free internet services doesn\u2019t mean that you're always providing secure internet service. An accepted usage policy (AUP) on your active portal ensures that users understand just that.\\n  * Some users of a free public wireless network may repeatedly connect, using the network on an almost continuous basis for bandwidth hogging activities like downloading music, videos, or other large files. For them you can provide ample bandwidth throttling. \\n\\n# Tornado\\n\\n  * Tornado is a Python web framework and asynchronous networking library. By using non-blocking network I/O, Tornado can scale to tens of thousands of open connections, making it ideal for long polling, Web-Sockets, and other applications that require a long-lived connection to each user.\\n\\n## Insight into IPTABLES\\n\\n  * iptables is a user-space application program that allows a system administrator to configure the tables provided by the Linux kernel firewall (implemented as different Netfilter modules) and the chains and rules it stores.\\n\\n  * Besides the obvious situations where you might imagine this would be useful, such as blocking long lists of \"bad\" hosts without worry of killing system resources or causing network congestion, IP sets also open up new ways of approaching certain aspects of firewall design and simplify many configuration scenarios.\\n\\n  * _IPSET_ : IP sets are a framework inside the Linux kernel, which can be administered by the ipset utility. Depending on the type, an IP set may store IP addresses, networks, (TCP/UDP) port numbers, MAC addresses, interface names or combinations of them in a way, which ensures lightning speed when matching an entry against a set.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n## Pre-requisite for this talk\\n\\n  * Basic Idea of IPSET and IPTABLES in Linux\\n  * Basic Idea of Tornado [If not! then don't worry you can check out sample from [here](http://www.tornadoweb.org/en/stable/guide.html). \\n  * Audience can bring their own Rasberry Pi (If they have one) else they can use their own Linux Machine for this workshop. \\n  * For people using their own laptop make sure you have Ubuntu 13.xx + installed on your system\\n  * And finally Hunger for Knowledge!\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * https://speakerdeck.com/aniketmaithani/wifi-captive-portal-using-raspberry-pi [Basic] \\n  * Code : will be updated soon.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nMy name is Aniket Maithani. I'll keep this short\\n\\n  * Works @Radiowalla Network Pvt. Ltd\\n  * Handles Development & Dev-Ops\\n  * B.Tech (CS&E) graduate from Amity University, Noida (UP)\\n  * Loves to travel\\n  * Blog during free time\\n  * Cricket Lover\\n  * \"CHAI\" addict\\n  * Plays Guitar too!\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [GitHub](https://github.com/aniketmaithani)\\n  * [Twitter](https://twitter.com/2aniketmaithani)\\n  * [Facebook](https://fb.com/aniket.maithani)\\n  * [LinkedIn](https://in.linkedin.com/in/aniketmaithani)\\n  * [Personal Blog](http://www.aniketmaithani.net)\\n\\n## Past Speaker @:\\n\\n  * [PyDelhi Conference 2017](https://www.youtube.com/watch?v=n5xUTcsrRns)\\n  * [BVP-IMR](http://www.bvimr.com/News_And_Event_Detail.aspx?nid=42)\\n  * [PyDelhi Meetup](https://github.com/pydelhi/talks/issues/38)\\n  * [PyDelhi Meetup](https://github.com/pydelhi/talks/issues/15)\\n  * [OSDC Conference](https://curiousdtu.wordpress.com/2014/03/24/bootconf-2014/)\\n  * [Webinar on Basics of GIT](https://www.youtube.com/watch?v=i6vKEo12KfE&t=902s)\\n  * [Webinar on Property Based Testing](https://www.youtube.com/watch?v=mz97xjV2TQM)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/creating-captive-portal-with-tornado-and-raspberry-pi~dwngb/",
			"speaker": {
				"name": "Aniket Maithani",
				"info": "",
				"photo": ""
			}
		},
		"09": {
			"title": "Complex network analysis using NetworkX - Graph Theory in Python",
			"description": "\\n\\n#### **Description:**\\n\\n[NetworkX](https://github.com/networkx/networkx) is a well maintained Python\\nlibrary for the creation, manipulation, and study of graphs and complex\\nnetworks. NetworkX provides data structures for networks along with graph\\nalgorithms, generators, and drawing tools. In particular NetworkX complements\\nPython's scientific computing suite of SciPy/NumPy, Matplotlib, and Graphviz\\nand can handle graphs in very large memory. NetworkX is recommended to be part\\nof every data scientist's toolkit.\\n\\nThe core algorithms that are included are implemented on very fast legacy\\ncode. Graphs are hugely flexible (nodes can be any hashable type), and there\\nis an extensive set of native IO formats.\\n\\nThe workshop would be focused on the basic usage of NetworkX in manipulation\\nof Graphs. After that, we would show some real scientific usage of NetworkX\\nand deal with one or two implementations right on hand.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Beginner-level familiarity with Graphs\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * [Notebooks used at SciPy India 2015 and VPCOE (University of Pune) tutorials on NetworkX](https://github.com/OrkoHunter/notebooks/tree/master/NetworkX)\\n  * [Slides used at SciPy India 2015](https://docs.google.com/presentation/d/1KrrG5ZZt9ShS7KFptAwYWogzuG1MWs01Bj4fV-7XN4Q/edit?usp=sharing)\\n  * [NetworkX Repository](https://github.com/networkx/networkx)\\n  * [NetworkX notebooks](https://github.com/networkx/notebooks)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI (Himanshu Mishra) am a fourth year undergrad student at IIT Kharagpur\\npursuing Mathematics and Computing. I have worked on NetworkX as a [Google\\nSummer of Code 2015](https://www.google-\\nmelange.com/gsoc/project/details/google/gsoc2015/orkohunter/5707702298738688)\\nstudent. I am currently a GSoC 2017 mentor under Python Software Foundation\\n(Timelab) where I was a [GSoC\\n2016](https://summerofcode.withgoogle.com/archive/2016/projects/4644645548064768/)\\nstudent.\\n\\nI am passionate about Software and Python.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [GitHub](https://github.com/OrkoHunter)\\n  * [Website](https://orkohunter.net)\\n  * [Blog](https://medium.com/@OrkoHunter)\\n  * [Talk at SciPy 2017, Austin TX](https://youtu.be/7tcJi378B2M)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/complex-network-analysis-using-networkx-graph-theory-in-python~e0XVe/",
			"speaker": {
				"name": "Himanshu Mishra",
				"info": "",
				"photo": ""
			}
		},
		"10": {
			"title": "Kubernetes 101 Workshop",
			"description": "\\n\\n#### **Description:**\\n\\nContainers are now matured and becoming the detault choice to deploy\\nmicroservices. We can bring our application up, scale up & down in no time\\nwith container orchestrators like [Docker\\nSwarm](https://docs.docker.com/engine/swarm/) and\\n[Kubernetes[(https://kubernetes.io). In this workshop we\u2019ll explore\\n[Kubernetes](https://kubernetes.io) and look at how we can use it to deploy a\\npython based micro-service application. In the workshop we would cover :-\\n\\n  * General Container Orchestration \\n  * Kubernetes Architecture\\n  * Kubernetes Building Blocks like Pods, Deployments, Replicasets, Services etc\\n  * Deploy All in One Kubernetes using Minikube\\n  * Deploy a standalone application \\n  * Deploy a micro-services based application \\n  * Scale the application \\n  * Kubernetes Community\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Basic Knowledge to Docker\\n  * Basic Knowledge to Flask\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * [Kubernetes 101 Presentation](https://drive.google.com/file/d/0B1roRn8kg1SQYWxkclY3ZWt5Wk0/)\\n  * [Kunernetes course on Edx](https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x), which I authored for the Linux Foundation \\n  * [Kubernetes 101 Lab](https://github.com/cloudyuga/kubernetes101)\\n  * Blog post on [Kubernetes 101 workshop, I did at at RootConf'17](https://cloudyuga.guru/blog/rootconf-booths-experience-and-kubernetes-workshop/)\\n\\n\\n\\n#### **Speaker Info:**\\n\\n**Neependra Khare**\\n\\nNeependra Khare is Founder and Principal Consultant at\\n[CloudYuga](https://cloudyuga.guru). CloudYuga provides training and\\nconsulting on Docker, Kubernetes, GO Programming etc. He is one of the [Docker\\nCaptain](https://www.docker.com/community/docker-captains) as well and running\\n[Docker Meetup Group in Bangalore](https://www.meetup.com/Docker-Bangalore/)\\nfor around 4 years. In 2015 he authored a book on Docker, Docker Cookbook. In\\n2016 he co-authored a course on [Cloud Infrastructure Technologies at Edx for\\nLinux Foundation](https://rootconf.in/2017/edx.org/course/introduction-cloud-\\ninfrastructure-linuxfoundationx-lfs151-x). Recently he authored a course on\\n[Kubernetes on Edx](https://www.edx.org/course/introduction-kubernetes-\\nlinuxfoundationx-lfs158x), for the Linux Foundation.\\n\\n**Praveen Kumar**\\n\\nPraveen Kumar is a Software Engineer currently working at Red Hat. At Red Hat\\nhis focus is to create tools around container ecosystem and Dockerfiles for\\ndifferent services. In his free time he contribute to Fedora project as RPM\\npackager. He has been a speaker at FUDCon, GNUnify, Flock, FOSSAsia, Jenkins\\nUser Conference, Docker-Meet and delivered talks on Docker, Ansible, RPM\\npackaging, Git, Jenkins and various other topics.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n**Nependra Khare**\\n\\n  * [Edx Kubernetes Course](https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x)\\n  * [GitHub](https://github.com/nkhare/)\\n  * [Personal Webiste](http://neependra.net)\\n  * [Twitter](https://twitter.com/neependra)\\n  * [LinkinIn](https://www.linkedin.com/in/neependra/)\\n\\n**Praveen Kumar**\\n\\n  * [Fedora Profile](https://fedoraproject.org/wiki/User:Kumarpraveen)\\n  * [GitHub](https://github.com/praveenkumar)\\n  * [Blog](http://kumar-pravin.blogspot.in/)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/kubernetes-101-workshop~b8OWa/",
			"speaker": {
				"name": "Neependra Khare",
				"info": "",
				"photo": ""
			}
		},
		"11": {
			"title": "Introduction to Bokeh",
			"description": "",
			"type": "",
			"cfp": "",
			"speaker": {
				"name": "Peter Wang",
				"info": "",
				"photo": ""
			}
		},
		"12": {
			"title": "Walkthrough cpython 3.6 source code",
			"description": "\\n\\n#### **Description:**\\n\\nThis talk will be an introduction to cpython from a source code level. We will\\nwalk through the source code of python from the parser, compiler, assembler\\nand interpreter phases. We will also understand the design of the garbage\\ncollector, memory allocator from a source code perspective. We shall also\\nexplore the different design philosophies of cpython. There will be special\\nemphasis on python objects such as lists, tuples, dictionaries etc and their\\ndesign internals. This talk is for people who are interested to explore how\\ncpython works internally.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  1. Python source code.\\n  2. gdb\\n  3. eclipse latest version\\n  4. linux\\n  5. make\\n\\n\\n\\n#### **Content URLs:**\\n\\nPlease read the books available for free download from\\n\\n<http://intopython.com>\\n\\nThe books are authored by the same speaker.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am Prashanth Raghu and my interest in python began back in 2009 when I was\\nstudying at PES University, Bangalore. I used python as a part of my\\ninternship project in my final year. It was used to develop a hybrid cloud app\\nwith the web front end designed in PHP and monitoring and load testing on\\npython. I was a Google Summer of Code scholar for the year 2014. ( My work:\\nhttps://github.com/openstack/zaqar/tree/master/zaqar/storage/redis ).\\n\\nI studied at National University of Singapore and did my Masters in Wireless\\nComputation with a research paper between 2013-2014. I was struck by a rare\\ndisease called Steven Johnson Syndrome in 2015 due to this my startup failed.\\nAt this crucial time I decided to do something of my interest and opened up\\nthe source code of python 2.7. I was amazed at the simplicity yet profoundness\\nof the architecture and decided to share my views with the world. And the\\nresult of my efforts for a couple of months has resulted into the book\\n\u201cInternals of Cpython 2.7\u201d and \u201cInternals of Cpython3.6\u201d available as a free\\ndownload under CC 4.0 license.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * <https://github.com/openstack/zaqar/tree/master/zaqar/storage/redis> \\- My contribution as a part of Google summer of code\\n  * <http://intopython.com> \\- my technical blog on python source code\\n  * <https://www.linkedin.com/in/prashanthraghu/>\\n  * <http://bangalore.python.org.in/blog/2017/06/17/jun-talks/> \\- Video of my talk at Bangpypers Jun 2017 meetup. \\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/walkthrough-cpython-36-source-code~azq5e/",
			"speaker": {
				"name": "Prashanth Raghu",
				"info": "",
				"photo": ""
			}
		},
		"13": {
			"title": "Binary Analysis and Exploitation using Python",
			"description": "\\n\\n#### **Description:**\\n\\nPython now has a lot of interesting libraries that can be used together to do\\nBinary Analysis and exploitation. We'll be using the great capstone engine\\nalongside, pyelftools and pefile to analyse a binary programatically.\\nAnalyzing includes getting information in the headers, assembly in the code\\nsection, imports, dynamic libraries and lots of other stuff. The second part\\nof the talk will be on Exploitation, where we'll try to exploit a buffer\\noverflow vulnerability on a linux application (with ASLR, Stack Cookies and\\nNX). We'll use pwntools and RopGadget . py to generate an exploit.\\n\\nI have written a blog post about how to use pyelftools and capstone engine to\\nreverse a simple elf crackme. Check it out here: http://anee.me/reversing-an-\\nelf/\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Interest in computer security\\n  * Basic knowledge about ELFs and PE\\n  * Knowledge about buffer overflows\\n\\n\\n\\n#### **Content URLs:**\\n\\n[https://anee.me/reversing-an-elf-from-the-ground-\\nup-4fe1ec31db4a](https://anee.me/reversing-an-elf-from-the-ground-\\nup-4fe1ec31db4a/)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am a recent CS grad from IIIT Delhi. I am currently working with DirectI as\\na DevOps engineer. I participate in a lot of CTFs and I love to work with\\nBinaries, trying to understand what they do and how to go about exploiting\\nthem. I also have experience in Network Security and anonymity and am\\ncurrently working on a research project on Decoy Routing. Besides that I\\nreally love opensource. I have contributed to a lot of organizations including\\nLibav, KDE, Sugarlabs, Radare2. I have participated in GSoC before and have\\nbeen winner of Google Code in 2012 and 2011.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * Github: <https://github.com/lionaneesh>\\n  * Website: <http://anee.me>\\n  * Mail: lionaneesh-at-gmail\\n  * Linkedin: [linkedin.com/in/aneeshdogra](http://linkedin.com/in/aneeshdogra)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/binary-analysis-and-exploitation-using-python~ergBa/",
			"speaker": {
				"name": "Aneesh Dogra",
				"info": "",
				"photo": ""
			}
		},
		"14": {
			"title": "Pyspark - Big Data applications using Python and Spark",
			"description": "\\n\\n#### **Description:**\\n\\nHere is the high level outline for the workshop:\\n\\n  * Revision of basic python programming\\n  * Overview of Big Data eco system\\n  * Data Engineering at scale with Spark core APIs using Python as programming language\\n  * Overvew of Spark SQL and Data Frames\\n  * Development life cycle and execution life cycle\\n\\nTraining will be provided using state of the art 10 node Big Data cluster. If\\nthis workshop is selected, all the participants for the workshop will get 1\\nmonth free access to our state of the art lab with content and other resources\\nto learn Big Data in detail.\\n\\nIf you are interested in this workshop please vote up to get shortlisted.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * A laptop (64 bit operating system and 4 GB RAM are highly desired)\\n  * Browser - Chrome or Firefox\\n  * Basic understanding of Python programming - loops, exception, file handling and collections\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttp://www.itversity.com/courses/apache-spark-using-python\\n\\n\\n\\n#### **Speaker Info:**\\n\\nDurga Gadiraju is technology evangelist and consultant with close to 14 years\\nof experience in building data driven applications at scale. For past 4 years,\\nDurga is primarily focused on Big Data in the areas of consulting, delivery\\nand training. His online platform itversity, is well known in IT community in\\nthe areas of Big Data and Cloud. itversity will be a free continuous learning\\nplatform for IT professionals.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * LinkedIN [Profile](http://%20https://www.linkedin.com/in/durga0gadiraju/)\\n  * YouTube [Channel](https://www.YouTube.com/itversityin)\\n  * [Blog](http://www.itversity.com)\\n  * Big Data [labs](https://labs.itversity.com)\\n  * Support through [Forums](http://discuss.itversity.com)\\n  * Github [account](https://github.com/dgadiraju)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/pyspark-big-data-applications-using-python-and-spark~b44kb/",
			"speaker": {
				"name": "Itversity Training",
				"info": "",
				"photo": ""
			}
		},
		"15": {
			"title": "Deep Learning with Tensorflow : Techniques for achieving optimal model performance.",
			"description": "\\n\\n#### **Description:**\\n\\nGiven enough data, lots of compute power and a clear objective, deep learning\\nmodels are powerful predictive tools that can be applied to a wide range of\\ntasks. Getting the best possible performance out of deep learning models\\nhowever, can take some work. While having more data to train the network on is\\nalways beneficial, carefully chosen model architectures and hyperparameters\\ncan yield faster and better convergence.\\n\\nThis workshop will be a tour of the important techniques that can be used to\\nget the best results from your deep learning models. The models will be\\nconstructed using Tensorflow and make use of Python 3.6. (Keras may also be\\nused to speed things up if suitable)\\n\\nWe will review a broad list of topics in the workshop, including:\\n\\n  * Weight initialization strategies\\n  * Batch Normalization\\n  * Dropout\\n  * Choice of optimizers\\n  * A discussion of activation functions\\n  * Optimizer hyperparameters\\n  * Model hyperparameters\\n  * Model architectures for specific tasks (CNNs, RNNs, GANs etc.)\\n\\n\\n\\n#### **Prerequisites:**\\n\\nBasic familiarity with neural networks will be a necessary prerequisite for\\nthe workshop. We will also be visualising model learning curves so previous\\ndata analysis/visualisation experience in python would be beneficial.\\n\\nIdeally, someone who is attending the workshop will have worked with neural\\nnetworks before and understands backpropagation and gradient descent. If\\nyou're not familiar with these topics but have a strong interest in deep\\nlearning, the following resources are great starting points:\\n\\n  * [Michael Nielsen's Book](http://neuralnetworksanddeeplearning.com) (Great for understanding backpropagation)\\n  * [Andrew Trask's blog](http://iamtrask.github.io) (neural network implementations in pure python)\\n  * [Tensorflow tutorials](https://www.tensorflow.org/get_started/get_started)\\n\\nSoftware Requirements:\\n\\n  * Python 3.6\\n  * Numpy 1.12+\\n  * Tensorflow 1.1+\\n  * Matplotlib 2.0.2\\n  * Seaborn 0.7+\\n\\n\\n\\n#### **Content URLs:**\\n\\nThe slides for the workshop will be put up soon.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI'm an economics graduate who found his passion for programming and experience\\nin economics merging together in machine learning. I've been working with\\nPython for the past 3 years and till recently was working as a Data Scientist\\nat Adpushup (a Microsoft Accelerator backed startup based in New Delhi).\\n\\nAlong with researching and implementing machine learning models, I've worked\\non big data applications developed using Spark and Spark Streaming.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [Blog](http://sahilsingh.org)\\n  * [LinkedIn](https://www.linkedin.com/in/sngsahil)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/deep-learning-with-tensorflow-techniques-for-achieving-optimal-model-performance~dRkYe/",
			"speaker": {
				"name": "sngsahil",
				"info": "",
				"photo": ""
			}
		},
		"16": {
			"title": "Python packages",
			"description": "\\n\\n#### **Description:**\\n\\nAll of our scripts need to eventually grow up into packages. Over the course\\nof this workshop, I'll help grow your script/scripts into fully fledged\\npackages.\\n\\nWe will start with a basic `setup.py` file and understand how installing a\\npackage makes it easy to use. We will look at examples of how to organise our\\npackage and understand how the organisation helps in understanding the\\npackage. We will use entry points to make your package more accessible. We\\nwill learn how GitHub can be used to host and share your package and what role\\nGit plays. We will understand the role of Continuous Integration services.\\nFinally, we will build and upload eggs & wheels for your package to PyPI.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nIt would help if the participants had a basic understanding of Python syntax.\\nIt will also help if the participants knew how to use Git and how to navigate\\nGitHub. Neither is a concrete requirement though.\\n\\n\\n\\n#### **Content URLs:**\\n\\nThe workshop will extend and elaborate on slides from an earlier talk -\\nhttps://github.com/rahulporuri/talks/blob/master/python_packages.pdf\\n\\nGit and GitHub will also be introduced and used for the workshop; slides from\\nan earlier workshop are -\\nhttps://github.com/rahulporuri/talks/blob/master/git_and_github.pdf\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am a Scientific Software Developer at Enthought. By day, I work on\\nEnthought's Product offerings. I have a background in Physics. I like giving\\ntalks and conducting workshops because researching the topic increases my\\nunderstanding. I've been (semi-) active in the Python community in Pune over\\nthe last year and I've given talks at local meetups and organized workshops.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nLinks to slides and Jupyter Notebooks for some of the talks/workshops I\\nconducted over the last year - https://github.com/rahulporuri/talks/\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/python-packages~dPr2a/",
			"speaker": {
				"name": "Rahul Poruri",
				"info": "",
				"photo": ""
			}
		},
		"17": {
			"title": "Deep Learning for NLP from scratch",
			"description": "\\n\\n#### **Description:**\\n\\n**King - Man + Woman = Queen**\\n\\nThe most famous example of word vectors paint an optimistic picture where\\ncomputers can represent word into vectors which can be used to infer\\nsimilarity. But can we extend it to sentences or to documents? How did word\\nvectors come into existence? What are its utilities?\\n\\nThough most of the people use [Mikolov et al's\\nWord2Vec](https://arxiv.org/abs/1301.3781) as a blackbox and train by:\\n\\n    \\n    \\n    import gensim\\n    sentences = [['content', 'of', 'first', 'sentence'], ['content', 'of', 'second', 'sentence'], ... , ['content', 'of', 'nth', 'sentence']]\\n    model = gensim.models.Word2Vec(sentences)\\n    \\n\\nAnd never know what is cooking inside the hood. This talk would cover a very\\nbasic implementation of Word2Vec, a small tutorial of how to use Gensim to\\ntrain your own word vectors. Building on this we would build vector\\nrepresentation of sentences. We would meanwhile learn about the novelty of\\nclassical and deep learning techniques.  \\nAfter learning all this we would explore the application of [Word Movers'\\nDistance](https://github.com/mkusner/wmd) for Information retrieval.  \\nThough these terms sound new, but this talk would build from the very\\nbasics(arrays as vectors) and myself being a programmer, along with Deep\\nLearning enthusiast, would focus more on a progammer's perspective.\\n\\nSlides:\\n[slides](https://docs.google.com/presentation/d/1ttn4fIfqvEqE5FhlB3l1lDPQ1JvZYu6ikz-\\nxmoEAD9Y/edit?usp=sharing)  \\nIPython notebook: [repo\\nlink](https://github.com/nishnik/word_embeddings_slides)\\n\\nCoverage of the talk:\\n\\n  1. Introduction to NLP -> 5 minutes\\n  2. Tokenization, Stemming and Lemmatization -> 15 minutes (5-7 minutes of Hands on session)\\n  3. Brief intro of POS and NER -> 5 minutes\\n  4. Word Embeddings (Theory and Motivation) -> 5 minutes\\n  5. Word Embeddings (Hands on)\\n    1. Basic Implementation -> 10 minutes\\n    2. Gensim based Implementation (Meanwhile explaining the possible use cases) -> 10 minutes\\n  6. Introduction to Deep Learning and exciting stuff for future (10 minutes) ( _60 minutes over here_ )\\n  7. Small intoduction to Keras (Hands on) (5 minutes)\\n  8. Basics about one-hot encoding, and explaining the hello world of neural networks (5 minutes)\\n  9. Using Keras for learning word embeddings and a glimpse of Transfer Learning (Hands on) (20 minutes)\\n  10. Introduction to Sentence embedding (5 minutes)\\n  11. Word Movers' Distance for Information Retrieval (10 minutes)\\n  12. Remaining as buffer time\\n\\n\\n\\n#### **Prerequisites:**\\n\\nThe participants should have interest in Natural Language Processing. The talk\\nwould be basically from scratch, but comfortableness with linear algebra would\\nhelp.\\n\\nInstalled libraries:\\n\\n  * NLTK\\n  * Gensim\\n  * Keras\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * [Word embedding introduction and extending to cross lingual case - A blog post](https://medium.com/towards-data-science/cross-lingual-word-embeddings-what-they-are-af7987df6670)\\n  * [Brief introduction about setence embedding - A blog post](https://medium.com/towards-data-science/sentence-embedding-3053db22ea77)\\n  * [Gensim](https://github.com/RaRe-Technologies/gensim)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nThe speaker is a fourth year undergraduate student at IIT Kharagpur. A\\nrobotics and deep learning enthusiast, he spends his time writing\\n[blogs](https://medium.com/@nishantnikhil/) about Artificial Intelligence\\nwhere he was a top writer till June 2017 or teaching humanoid robots to walk\\nand kick at the [KRSSG Lab](http://krssg.in/) otherwise maintaining the\\n[college wiki](https://wiki.metakgp.org/w/Main_Page).\\n\\nHe is currenty a GSoC mentor for\\n[SymEngine/SymPy](http://github.com/symengine/symengine) where he was a GSoC\\nstudent in 2016. Furthermore, he has worked on Cross Lingual Word embeddings\\nat [UFAL Prague](https://ufal.mff.cuni.cz/), generating pattern of birds'\\nsongs at [ETH Zurich](https://www.ethz.ch/en.html) and hierarchical embeddings\\nat [Stony Brooks NYC](http://www.stonybrook.edu/).\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [Blog](https://medium.com/@nishantnikhil/)\\n  * [Github](https://github.com/nishnik)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/deep-learning-for-nlp-from-scratch~b8B2e/",
			"speaker": {
				"name": "Nishant Nikhil",
				"info": "",
				"photo": ""
			}
		},
		"18": {
			"title": "Applying Transfer Learning on Your Data",
			"description": "\\n\\n#### **Description:**\\n\\nHumans have great ability to generalize; we can very efficiently apply the\\nknowledge we learned in classrooms to real world problems. **Transfer\\nlearning** provides a similar capability to artificial neural networks. The\\nWorkshop will introduce the concept of 'Transfer Learning' described by Andrew\\nNg, the leading expert in Machine Learning as the \" **next driver of ML\\ncommercial success.** \" Transfer Learning is important because training deep\\nneural networks from scratch have two key requirements. First, we need a large\\nlabeled dataset; the second one requires computationally efficient hardware\\n(GPUs). While such immensely large data exists for some tasks and domains, in\\nmost cases the data are usually proprietary or expensive. Transfer Learning,\\nthe technique to use models pre-trained on one domain for another problem\\ndomain, provides the ability to use DNNs even when the dataset is small.\\nMoreover, Transfer learning requires less computation and thus can be done in\\nrespectable time using CPUs as well.\\n\\nThe workshop will cover following topics:\\n\\n  * Introduction to Transfer Learning \\n  * Application of Transfer Learning\\n  * Transfer Learning Scenarios \\n  * Applying Transfer using Keras and Tensorflow\\n\\nAnd finally, we will have hands on session demonstrating how to use Xception\\nand Inception networks for Dog breed Recognition.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Anaconda installed (Python =3.5)\\n  * Tensorflow 1.x\\n  * Numpy\\n  * Matplotlib\\n  * Pandas\\n  * Seaborn\\n  * For the sake of convenience and due to limited time, Speaker, will also provide environment 'yml' files (Windows10, Ubuntu14.04/16.04, Mac OS X)\\n\\n\\n\\n#### **Content URLs:**\\n\\nTo make best use of the workshop it would be appreciated if participants are\\nwell versed with Anaconda, Python and understand Convolution Neural Networks.\\nThe information necessary can be accessed via following links\\n\\n  * How to manage Anaconda Environments: <https://conda.io/docs/user-guide/tasks/manage-environments.html>\\n  * Convolutional Neural Networks [here](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/) and [here](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)\\n\\n\\n\\n#### **Speaker Info:**\\n\\n**Amita Kapoor** : Amita Kapoor is Associate Professor in the Department of\\nElectronics, SRCASW, University of Delhi. She has been actively teaching\\nneural networks for last twenty years. She did her Masters in Electronics in\\nthe year 1996, and her PhD in the year 2011. During the course of her PhD, she\\nwas awarded prestigious DAAD fellowship to pursue a part of her research work\\nin Karlsruhe Institute of Technology, Karlsruhe, Germany. She had been awarded\\nbest Presentation Award at International Conference Photonics 2008 for her\\npaper. She is a member of professional bodies like OSA (Optical Society of\\nAmerica), IEEE (Institute of Electrical and Electronics Engineers), INNS\\n(International Neural Network Society), ISBS (Indian Society for Buddhist\\nStudies). She has more than 40 publications in the international journals and\\nconferences. Her present research areas include Machine Learning, Artificial\\nIntelligence, Neural Networks, Photonics and Robotics.\\n\\n**Narotam Singh** : Narotam Singh has been with India Meteorological\\nDepartment, Ministry of Earth Sciences, India since 1996. He has been actively\\ninvolved with various technical programs and training of officers of GOI in\\nthe field of Information Technology and Communication. He did his post-\\ngraduation in the field of Electronics in 1996 and both Post graduate diploma\\nand Diploma in the field of Computer Engineering, in 1997 and 1994\\nrespectively. He is currently working in the enigmatic field of Neural\\nNetworks.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nAmita Kapoor: [Personal Website](http://www.dramitakapoor.com),\\n[Github](https://github.com/amita-kapoor),\\n[Linkedin](https://www.linkedin.com/in/amitakapoor/)\\n\\nNarotam Singh: [Personal Website](http://narotam.com/),\\n[Github](https://github.com/narotamsingh),\\n[Linkedin](https://www.linkedin.com/in/narotamsingh/)\\n\\n",
			"type": "workshop",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/applying-transfer-learning-on-your-data~eXqoa/",
			"speaker": {
				"name": "Amita Kapoor",
				"info": "",
				"photo": ""
			}
		},
		"19": {
			"title": "Keynote - Mentoring : What, Why, How by Noufal Ibrahim",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"20": {
			"title": "Child Care",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"21": {
			"title": "Tea",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"22": {
			"title": "Visualizing machine learning algorithms in Python",
			"description": "\\n\\n#### **Description:**\\n\\nMachine learning algorithms are increasingly black-box models. However, their\\noutputs are business data that humans need to understand and act upon.\\n\\nFor example, if a clustering model suggests 4 customer clusters, how do we\\nidentify and characterize these? If a random forest model suggests a pattern\\nof classification, how do we understand the dominant factors and the\\nirrelevant ones?\\n\\nThese topics fall under the umbrella of model visualization -- where the\\ninputs, process and output of machine learning models are the topic of\\nunderstanding.\\n\\nThis talk explores some of the prevalent ways of visualizing machine learning\\nmodels.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nA basic understanding of ML models\\n\\n\\n\\n#### **Speaker Info:**\\n\\nAnand is a co-founder of Gramener, a data science company. He leads a team of\\ndata enthusiasts with skills in analysis, design, programming and statistics.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [Videos of previous talks](https://www.youtube.com/playlist?list=PLrn2FHBzHtaOGyyqkShkRsAzBCD7fFBqO)\\n  * [Slides of previous talks](https://www.slideshare.net/gramener)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/visualizing-machine-learning-algorithms-in-python~eE64a/",
			"speaker": {
				"name": "Anand S",
				"info": "",
				"photo": ""
			}
		},
		"23": {
			"title": "",
			"description": "",
			"type": "talk",
			"cfp": "",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			}
		},
		"24": {
			"title": "HTTP Bottom Up - Live!",
			"description": "\\n\\n#### **Description:**\\n\\nA deep-dive, live coding talk to explore everything that happens behind the\\nscenes of your favorite web framework.\\n\\nThis talk explores building web applications starting all the way from bare\\nsockets, without using any framework. Even though this is not the most\\nproduction way to build web applications, this exercise will give a chance to\\nobserve and understand everything that happens behind the scenes of any web\\napplication.\\n\\n### Outline\\n\\n  * Understand the difference between the Internet and World Wide Web\\n  * Play with some Internet Applications\\n  * Network programming and concurrency patterns\\n  * Understand how web browser and web server work\\n  * Build a web server\\n  * Understand WSGI\\n  * Build a web framework\\n  * Write a simple webapp using the web framework built above\\n\\n\\n\\n#### **Prerequisites:**\\n\\nOpen mind and curiosity.\\n\\n\\n\\n#### **Content URLs:**\\n\\nThis is going to be a live coding talk. I'm not planning to use any slides.\\n\\nI offer this as a 2-day workshop and notes from one my earlier workshops are\\navailable at:  \\n<https://github.com/anandology/httpbottomup>\\n\\n\\n\\n#### **Speaker Info:**\\n\\n[Anand](http://anandology.com/) has been crafting beautiful software since a\\ndecade and half. He\u2019s now building a data science platform,\\n[rorodata](http://rorodata.com/), which he recently co-founded. He regularly\\nconducts advanced programming courses through [Pipal\\nAcademy](https://pipal.in/). He is co-author of web.py, a micro web framework\\nin Python. He has worked at Strand Life Sciences and Internet Archive.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n<http://anandology.com/>\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/http-bottom-up-live~bDWka/",
			"speaker": {
				"name": "Anand Chitipothu",
				"info": "",
				"photo": ""
			}
		},
		"25": {
			"title": "Making Of NextGen Fintech: Insights From Visible Alpha Tech Stack (Sponsored Talk)",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "Visible Alpha",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"26": {
			"title": "Liberating tabular data from the clutches of PDFs",
			"description": "\\n\\n#### **Description:**\\n\\nBudget Documents are moral documents that represent the priorities and values\\nof the states and its governing bodies. Unfortunately these documents are\\npublished in unstructured PDF formats which makes it difficult for\\nresearchers, economists and general public to analyse and use this crucial\\ndata.\\n\\nIn this session will delve into how we can create a data pipeline and leverage\\ncomputer vision techniques to parse these documents into clean machine-\\nreadable formats by leveraging libraries like OpenCV, numpy, pandas, PyPDF2,\\ntabula and poppler-pdf-to-text\\n\\n**Outline**\\n\\n  * Setting the scene\\n  * Issues with Indian Budget Documents\\n  * Extracting Tables with boundaries.\\n    * Detecting Table Boundaries using OpenCV\\n    * Leveraging Open Source Tools like \u201cTabula\u201d\\n  * What about tables without boundaries ?\\n  * Extracting information from tables without boundaries\\n    * Geometrical features using OpenCV library\\n    * Textual features using \u201cpdf to text\u201d poppler\u2019s version\\n  * Building a pipeline to detect table components\\n    * Headers\\n    * Number Cells\\n    * Text Based Cells / Groupings\\n  * Detecting Table layout\\n    * Detecting rows\\n    * Detecting columns\\n    * Where each component lies\\n  * Extracting tables split across Pages\\n  * Building a base for machine learning models while doing so.\\n  * Open Research using Jupyter Notebooks\\n  * How you can contribute ?\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Python 2.7\\n  * pandas\\n  * numpy\\n  * Basic Image Manipulation using OpenCV\\n\\n\\n\\n#### **Content URLs:**\\n\\nRepo: https://github.com/heaven00/pycon_delhi_2017  \\nSlides: https://heaven00.github.io/pycon_delhi_2017\\n\\n\\n\\n#### **Speaker Info:**\\n\\nJayant works with Open Budgets India to help make India's Budgets open, usable\\nand easy to comprehend and during the weekends he works with Datakind as a\\ncore team member to help make social organisations data driven.\\n\\nJayant is also a machine learning enthusiast and enjoys good food and games.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * https://github.com/cbgaindia/parsers\\n  * https://github.com/cbgaindia/scrapers \\n  * https://github.com/heaven00\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/liberating-tabular-data-from-the-clutches-of-pdfs~dRjwd/",
			"speaker": {
				"name": "jayant",
				"info": "",
				"photo": ""
			}
		},
		"27": {
			"title": "Reducing dead code ratio of your project with vulture",
			"description": "\\n\\n#### **Description:**\\n\\nMaintaining a high level of code quality is important for any serious project.\\nOne aspect of this is ensuring that all code is actually used. There are many\\nreasons for dead code ending up in a project. The most common is refactoring,\\nbut another is misspellings, which are only detected at runtime for dynamic\\nlanguages. Finding and removing dead code allows to keep the code base clean\\nand reduces bugs.\\n\\nThis talk is focussed on how we can use Vulture to find dead code. It helps\\nyou find unused code in Python programs and it is useful for cleaning up and\\nfinding errors in large code bases. If you run Vulture on both your library\\nand test suite you can find untested code. Due to Python's dynamic nature,\\nstatic code analyzers like Vulture are likely to miss some dead code. Also,\\ncode that is only called implicitly may be reported as unused. Nonetheless,\\nVulture can be a very helpful tool for higher code quality.\\n\\nOne part of this talk is to discuss how to automate testing for dead code with\\nVulture. There are quite a few options available:\\n\\n  * Adding vulture to your continuous integration testing.\\n  * A script using the Vulture API for custom tests.\\n  * [VultureBear](https://github.com/coala/coala-bears/blob/master/bears/python/VultureBear.py): Integration with [coala](https://coala.io) \\- a static code analysis tool.\\n  * Integration with automatic analysis tools like [GitMate](https://gitmate.io), etc. for automatic code-reviews with native support for Github and Gitlab.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * python (any version would do)\\n  * pip\\n\\nHaving coala installed will be a plus.\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * [vulture](https://github.com/jendrikseipp/vulture)\\n\\n  * [coala.io](https://coala.io)\\n\\n  * [GitMate](https://gitmate.io)\\n\\n\\n\\n#### **Speaker Info:**\\n\\n**Rahul Jha**\\n\\nHe is currently pursuing B.Tech. (ECE) and has been developing software for 3\\nyears now. He is an Open source enthusiast and as part of his GSoC project, he\\ndeveloped the vulture API for easy integration with coala.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nYou may find more about Rahul here:\\n\\n  * <https://github.com/RJ722>\\n  * <https://rj722.tech>\\n\\nThe best way to contact him is through e-mail: rahul722j@gmail.com,\\nrahul@rj722.tech\\n\\nSome of his work:\\n\\n  * <https://github.com/jendrikseipp/vulture/commits?author=RJ722>\\n  * <https://github.com/coala/coala-bears/commits?author=RJ722>\\n  * <https://github.com/coala/coala/commits?author=RJ722>\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/reducing-dead-code-ratio-of-your-project-with-vulture~e9GYb/",
			"speaker": {
				"name": "Rahul Jha",
				"info": "",
				"photo": ""
			}
		},
		"28": {
			"title": "Building microservices with firefly",
			"description": "\\n\\n#### **Description:**\\n\\n`firefly` is an open source micro framework to deploy Python functions as web\\nservices. `firefly` was created with the aim of simplifying the deployment\\nMachine Learning models as RESTful API. But as fate would have it, it became\\nour favourite tool for building microservices. `firefly` takes care of\\nprocessing the HTTP requests, forwarding the data to the python functions and\\nencoding the result back to a HTTP request. It also has data validation,\\nauthentication support, transfering any type of file. You can also define a\\nconfiguration file specifying the URL resource structure resulting in an\\nelegant RESTful API.\\n\\nIt comes with a client library that makes calling remote functions calling as\\neasy as calling functions present locally. It is a WSGI application and can be\\ndeployed and scaled through any WSGI server like `gunicorn`. There are many\\nother features in the pipeline like multiple authentication modes through the\\nplugin system.\\n\\nThis talk will focus on introducing `firefly`, it's notable features like\\nplugin support, building microservices efficiently with various examples.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nThe participants should have a basic notion of making web services and RESTful\\nAPI's.\\n\\n\\n\\n#### **Content URLs:**\\n\\nSlides outline:\\n\\n  1. About me\\n  2. Microservices Architecture\\n  3. Comparison with monolithic architecture\\n  4. Design Patterns\\n  5. Forces in Action\\n  6. Solution\\n  7. Examples\\n  8. Benfits\\n  9. When to use?\\n  10. Who uses?\\n  11. Firefly to the rescue\\n  12. What is firefly?\\n  13. Why use firefly?\\n  14. Code\\n  15. Run\\n  16. Deploy\\n  17. Use (Client)\\n  18. Authentication\\n  19. Data Validation\\n  20. Canonical URL's\\n  21. Plugins\\n\\nGithub: <https://github.com/rorodata/firefly>  \\nDocumentation: <https://firefly-python.readthedocs.io/>\\n\\n\\n\\n#### **Speaker Info:**\\n\\nThe speaker is Nabarun Pal, a final year undergraduate student at [Indian\\nInstitute of Technology Roorkee](http://iitr.ac.in). Currently, he is working\\nfor [rorodata](https://rorodata.com) which aims at providing data scientists a\\nplatform to build and deploy their models without the need of worrying about\\ninfrastructure, scalability, and performance. He is working on an Open Source\\nFunctions as a Service framework called\\n[firefly](https://github.com/rorodata/firefly).\\n\\nHe is passionate about software development. He can also talk about Internet\\nof Things, Electronics, Robotics with equal spirit. His journey with the field\\nof software and robotics started in his schooling days. He represents the\\ncollege in various Robotics competitions and was involved in projects related\\nto the above domains, brief of which can be found\\n[here](https://nabarun.in/Nabarun_Pal_SDE.pdf). He actively participates in\\nconducting open lectures for students in the domains of Introductory Robotics,\\nControl, AI and ML through a curated\\n[community](https://www.facebook.com/groups/mnrsectioniitr/) of around 2000\\nmembers. He is also speaking at [PyData Delhi\\n2017](http://www.pydata.org/delhi2017).\\n\\n\\n\\n#### **Speaker Links:**\\n\\nHomepage: <https://nabarun.in>  \\nLinkedIn: <https://www.linkedin.com/in/nabarunpal/>  \\nGithub: <https://github.com/palnabarun>\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/building-microservices-with-firefly~bWoob/",
			"speaker": {
				"name": "Nabarun Pal",
				"info": "",
				"photo": ""
			}
		},
		"29": {
			"title": "Panel Discussion 1",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"30": {
			"title": "Lightning Talks",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"31": {
			"title": "Sponsored Workshop/Talks 2",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"32": {
			"title": "Machine learning & NLP at Goibibo: Keytopic extraction and contextual sentiment analysis of 20 million reviews, and a customer assistance bot",
			"description": "\\n\\n#### **Description:**\\n\\n  * We, at Goibibo, extensively use Python as part of our app as well as data processing stack. \\n  * We receive a good volume of user generated content, and use natural language processing and machine learning to derive insights and data from them for our products.\\n  * The talk would cover how we build our user review analyzer system which **extracts keytopics/keywords from 20 million user reviews** and user sentiments about that keytopic. For example : How we detect that \"the rooms were very spacious\" is a positive experience for a consumer, or that a particular hotel has an amazing candle light dinner.\\n\\n  * The talk would cover language processing in Python using inbuilt/installed python modules, and dedicated NLP libraries like **NLTK and spaCy** , and sentiment analysis/categorization done by **Scikit-learn**.\\n\\nThis feature can be viewed and experienced on Goibibo mobile apps (\\n[Android](https://play.google.com/store/apps/details?id=com.goibibo)/\\n[iOS](https://itunes.apple.com/in/app/goibibo/id631927169?mt=8)) and visiting\\na hotel's product page.\\n\\n![enter image description\\nhere](https://gos3.ibcdn.com/keytopics-1504185022.jpg)\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Intermediate level knowledge of Python is beneficial, however the concepts are language agnostic .\\n  * Knowledge of NLTK , spaCy and scikit-learn is a plus.\\n\\n\\n\\n#### **Content URLs:**\\n\\nTalk presentation link : https://prezi.com/view/m2Fe65t1RTuQK2s1LZrC/\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am Dhruv Pathak, a python enthusiast. I currently work at Goibibo as VP of\\nEngineering, where we ship many evolving and high scale products using Python.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * https://stackoverflow.com/users/533399/dhruvpathak\\n  * https://www.linkedin.com/in/dhruvpathak\\n  * https://github.com/dhruvpathak\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/machine-learning-nlp-at-goibibo-keytopic-extraction-and-contextual-sentiment-analysis-of-20-million-reviews-and-a-customer-assistance-bot~aMW1d/",
			"speaker": {
				"name": "Dhruv Pathak",
				"info": "",
				"photo": ""
			}
		},
		"33": {
			"title": "Creating Cross Connectivity for Scalability - Hybrid Apps",
			"description": "\\n\\n#### **Description:**\\n\\nEvery programming language has its own X-factor for which it is popular and\\npurposely meant for, for example, Concurrency , which is quite an issue Python\\n, can be done efficiently in Golang (which is popular for its concurrency by\\nusing Go Routines).\\n\\nSimilarly, Another example for Real Time Communication(RTC) is Erlang, though\\nit can be done in Python as well, but , Erlang is the most efficient in Real\\nTime Communication. To enlighten it, most of us has used \"web.whatsapp.com\"\\nwhich is a live and most widely used application of Erlang.\\n\\nAnd Similarly, Python, is the most versatile language which can implement\\nalmost any task of Computer Science, no matter, from Embedded to Data Mining.\\nBut while doing, as a Pure Python developer(Pythonista), I have to\\n**compromise with the resource consumption and efficiency**.\\n\\nBut, just imagine how amazing the world would be if combine all the rich\\nfeatures of Golang, Erlang etc. other programming languages to one central\\npoint i.e. Python which and eventually helps to develop Hybrid apps with less\\nresource consumption(achieving scalability). **And at the same point , we will\\nbe sticking to our favourite platform i.e. \"Python\".**\\n\\n**Scalability** , which is the hot topic of the scenario, since, now we have a\\nmassive number of people waiting for us everyday to develop something new for\\nthem, which would help to reduce the strain in their day to day life and we\\nhave to take care that our developed services shouldn't crash when they needed\\nit the most , that too at a reasonable cost.\\n\\n_Why Sticking to Python ?_\\n\\nBecause of the **easiness of doing from anything to everything on Python**. As\\nfar as I have tried programming languages, undoubtedly, Python is the most\\nquick going, less code, simple syntax.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Basic knowledge of Python\\n  * Basic Knowledge of Protocols like http, udp, tcp, protobuff etc. and RPCs like XMLrpc, JSONrpc etc.\\n  * Some awareness of Python GIL\\n  * Interest to learn something unsual and fascinating\\n\\n\\n\\n#### **Content URLs:**\\n\\nI've developed a couple of libraries to show the implementation of IDEA:\\n\\n  * https://github.com/chawlanikhil24/gopy\\n  * https://github.com/chawlanikhil24/goPyServer\\n\\n\\n\\n#### **Speaker Info:**\\n\\nNikhil is a jovial programmer who has been programming in Python for past 3\\nyears, and has been promoting Python heavily amongst the people, via the ways\\nof SIGs, which he conducted under IEEE-NIEC. He has been a very active member\\nof IEEE-NIEC student branch of NIEC and has done many projects in IOT,\\nEmbedded Programming.\\n\\nApart from IEEE, he has been doing some other projects on Socket Programming,\\nMicroservices-an implementation of Service Oriented Architecture(SOA), Data\\nmining, Data Visualisation and has been a part of many startups, developing\\ntheir platforms particularly on Flask and Django.\\n\\nCurrently he is an intern at \"The Linux Foundation\", working on Blockchain\\nTechnology for a project named Hyperledger, mentored by people at Huawei,\\nChina and IBM, China.\\n\\nApart from Python, what fascinates him the most is: **Containers and\\nOrchestration**.\\n\\nHis aim is to contribute to a future full of fruitful technologies which works\\nlightning fast and benefiting humanity.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  1. [Github](https://github.com/chawlanikhil24)\\n\\n  2. [Twitter](https://twitter.com/chawlanikhil24)\\n\\n  3. [LinkedIN](https://www.linkedin.com/in/chawlanikhil24/)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/creating-cross-connectivity-for-scalability-hybrid-apps~b2Gjd/",
			"speaker": {
				"name": "Nikhil Chawla",
				"info": "",
				"photo": ""
			}
		},
		"34": {
			"title": "Building single page javascript apps with Django, Graphql, Relay and React!",
			"description": "\\n\\n#### **Description:**\\n\\nI'm the author of a boilerplate called Reango.\\n\\nhttps://github.com/ncrmro/reango\\n\\nIt features a GraphQL backend powered by Django. Django then serves a Webpack\\ncompiled single page application built using React, Relay.\\n\\nIt features authentication using JWT tokens and with unit and browser tests.\\n\\nI'd like to give a talk on when and how to use such a stack as Reango.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nWhat an API is, the Django ORM, a bit of understanding of the difference\\nbetween server side and client side rendered front ends.\\n\\n\\n\\n#### **Content URLs:**\\n\\n[Reango Github Boilerplate](https://github.com/ncrmro/reango \"Reango Github\\nBoilerplate\")\\n\\n[Presentation\\nLink](https://drive.google.com/open?id=0B3Qoff7xwUhnanBEcThrR014NEU\\n\"Presentation\")\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI grew up in Houston Texas, I've owned and worked as Software Developer/IT\\nconsulting company for the last four years, I'm currently using this stack too\\nIn one of my business projects and was also hired to implement the Reango\\nstack for a company in Silicon Valley.\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/building-single-page-javascript-apps-with-django-graphql-relay-and-react~axoze/",
			"speaker": {
				"name": "Nicholas Romero",
				"info": "",
				"photo": ""
			}
		},
		"35": {
			"title": "How to Boost your Tensorflow model inference performance using  Asyncio.",
			"description": "\\n\\n#### **Description:**\\n\\nLately, there has been a lot of interest in Deep Learning(dl) and thanks to\\nframeworks like tensorflow anyone can implement dl-papers and create models.\\nBut unfortunately, the deployment patterns followed are mostly rudimentary\\nREST calls to the model or using tensorflow-serving, which is fine when you\\nare experimenting but when the model gets deployed and the requests start\\nflying, such methods will create a bottleneck in your Architecture. There are\\nobvious workarounds like running multiple model instances behind a load\\nbalancer, but what if there is a much better Pythonic way.\\n\\n**Actor and CSP patterns** have been around since the 70s(73 and 78\\nrespectively) but only a niche group has taken a keen look at them and since\\nthe introduction of asyncio from Python3.5 onwards, the Python ecosystem has\\nbeen opened up to these patterns in some _limited but useful forms_. **This\\ntalk will show these patterns and how they can be used to deploy Deep Learning\\nmodels in the right way** , ( _the reference to Deep Learning alone has been\\nintentional and relates to the[batching in\\ntensorflow](https://www.tensorflow.org/serving/serving_advanced)_ ). As to the\\nquestion of the credibility of these patterns, **Actor model is used by Erlang\\nand CSP model is used by Go** , yep we can write Python3 code like these\\nlanguages.\\n\\nThis talk is not about.\\n\\n  * **Microservices** , are good but you cannot have 1000's if not tens of thousands unique Microservices created on the fly, connected uniquely for each user.(A unique pipeline per user). Also, microservices have the downside of depending on an external message passing solutions(Redis, Celery, RabbitMQ) which add to the latency. \\n  * **Deep Learning algorithms** , as there are plenty of resources for the same, we are only looking at the model deployment perspective i.e. inference time optimization.\\n\\n**The proposed method is implemented using Python alone without any external\\ndependencies including 3rd party message passing solutions making it faster\\nand lighter than microservices.**\\n\\n\\n\\n#### **Prerequisites:**\\n\\nA basic idea of asyncio coroutines and if possible streams.\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI started using Python in 2014 to quickly hack together my master's thesis and\\nits been a steady relationship since then. Over the past few years, I have\\nbeen working on building scalable systems and deploying Data processing\\npipelines at scale.\\n\\nLately, I have been a part of a startup that offers Chatbot services and we\\nwere facing serious scale up issues, it was while solving these issues that I\\npicked up on the ideas for this talk. If you think of Chatbots, each\\nconversation is a unique data pipeline with each node depending on different\\nentities and topics and having its own states, these are difficult to model\\nusing prevalent graph traversal techniques in Python, thus the Actor/CSP model\\nwith asyncio.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [LinkedIn](https://www.linkedin.com/in/derrick-joseph-545566a4/)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/how-to-boost-your-tensorflow-model-inference-performance-using-asyncio~bWpnd/",
			"speaker": {
				"name": "Derrick Joseph",
				"info": "",
				"photo": ""
			}
		},
		"36": {
			"title": "Self-Healing Code: A Journey Through Auto-Remediation",
			"description": "\\n\\n#### **Description:**\\n\\nManaging modern Product Infrastructure and applications is daunting because\\nthe bigger the infrastructure, more complicated the operational challenges you\\nface. Things break, daemons die, services stop, clusters fall \u2013 not to mention\\nwriting the root cause analysis (RCA) documents and runbooks on how to fix the\\nsame problem in the future. If you keep on adding monitoring, you end up\\nhaving a huge pile of alerts and failures every day.\\n\\nTo ensure availability of product as you scale, either you automate or you\\ndie. This is where Auto- Remediation comes into picture.\\n\\nAuto-Remediation, or Self-Healing, is a workflow which triggers and responds\\nto alerts or events by executing actions that can prevent or fix the problem.\\n\\nThe simplest example of auto-remediation is restarting a service (let\u2019s say\\napache) when it\u2019s down. Imagine an automated action that is triggered by a\\nmonitoring system to restart the service and prevent the application outage.\\nIn addition, it creates a task and sends a notification so that the engineer\\ncan find the root cause during business hours, and there is no need to do it\\nin the middle of the night. Furthermore, the event-driven automation can be\\nused for assisted troubleshooting, so when you get an alert it includes\\nrelated logs, monitoring metrics/graphs, and so on.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  1. Basic knowledge of Python\\n  2. Basic Knowledge of Saltstack (Python based open source configuration management tool)\\n  3. Knowledge of Nagios\\n  4. Basic Bash or Python scripting knowledge\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://medium.com/adobe-io/self-healing-code-a-journey-through-auto-\\nremediation-60367eea312\\n\\nPresentation - https://speakerdeck.com/arusing/self-healing-code-a-journey-\\nthrough-auto-remediation\\n\\n\\n\\n#### **Speaker Info:**\\n\\nArun Singh is a seasoned Site Reliability Engineer & DevOps professional,\\ncurrently employed with Adobe Systems India Pvt Ltd. He has extensive\\nexperience in Linux administration, several monitoring tools, python and bash\\nprogramming, SQL and NoSQL databases etc. He has developed an expert level of\\nunderstanding in Saltstack, a configuration management tool. His recent work\\nhas been revolving around improving the efficiency and productivity of site\\nreliability engineers and devops professionals in day to day work scenario.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nhttps://www.linkedin.com/in/arun-kumar-singh-17119b40/\\n\\nhttp://arunblogger.com/\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/self-healing-code-a-journey-through-auto-remediation~dw2Xb/",
			"speaker": {
				"name": "arusing@adobe.com",
				"info": "",
				"photo": ""
			}
		},
		"37": {
			"title": "Boosting Python Web Applications with Protocol Buffers and GRPC",
			"description": "\\n\\n#### **Description:**\\n\\n![enter image description\\nhere](https://image.slidesharecdn.com/microservicessummittalk-1-31-170208170653/95/bringing-\\nlearnings-from-googley-microservices-with-grpc-varun-talwar-\\ngoogle-42-638.jpg?cb=1486576122)\\n\\nDo you know in the current micro services world, how to spot the critical\\nparts of a monolith and replace them with modern efficient technologies? Have\\nyou ever wondered how Google or Netflix scale their traffic? For all these\\nquestions you should know how you can boost your web applications using\\nProtocol Buffers and GRPC. Protocol Buffer is the data format that allows you\\nto efficiently compose and read messages in binary format over HTTP/2. GRPC is\\na transport mechanism which delivers the protocol buffers over the wire. In\\nthe recent days, businesses may integrate with third party systems. For that\\nto be smooth, any system can implement a micro service and others can consume\\nit and vice versa.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nKnowledge of JSON based REST services. Others will be covered in the talk.\\n\\n\\n\\n#### **Content URLs:**\\n\\nTalk's preliminary slides are here:\\n\\n<https://goo.gl/bb1RDh>\\n\\n\\n\\n#### **Speaker Info:**\\n\\n![enter image description here](https://challengepost-s3-challengepost.netdna-\\nssl.com/photos/production/user_photos/000/263/747/datas/profile.JPG)\\n\\nNaren Arya, currently working as Software Engineer 2 at Citrix R&D, India. He\\nis a Pythonista from the beginning. Currently joined the cloud services team\\nin Citrix in a full stack development role. He is well known with his Python\\nblog Impythonist. Gave many conference talks and presentations before. He is\\nwilling to share his knowledge of building micro services with Protocol\\nBuffers & GRPC. Naren previously worked at few innovative startups like\\nKnowlarity Cloud Telephony for integrating many different platforms using\\nDjango & BackboneJS.\\n\\nHe loves blogging on open source because it is the simplest way to explain\\nthings to the loving community. Apart from Python, he loves web development\\noverall, best practices of scaling etc.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n<https://github.com/narenaryan>\\n\\n<https://www.linkedin.com/in/narenarya/>\\n\\n<https://impythonist.wordpress.com/>\\n\\n<https://www.youtube.com/watch?v=NAwFrYcAY8Y>\\n\\n<https://medium.com/@narenarya>\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/boosting-python-web-applications-with-protocol-buffers-and-grpc~egQZb/",
			"speaker": {
				"name": "Naren",
				"info": "",
				"photo": ""
			}
		},
		"38": {
			"title": "Keynote - Python Community Principles by Elizabeth Ferrao",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"39": {
			"title": "Keynote by Peter Wang",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"40": {
			"title": "Sponsored Workshop/Talks 3",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"41": {
			"title": "Geospatial data science and analysis using ArcGIS API for Python",
			"description": "\\n\\n#### **Description:**\\n\\nAnalysts and data scientists can use the ArcGIS API in combination with data\\nscience libraries in Python for mapping, visualization and geospatial data\\nanalysis. This live-demo style talk will demonstrate how to perform\\nsophisticated vector and raster analysis, geocoding, map making, routing and\\ndirections using a Pythonic API along with Jupyter notebooks and Pandas.\\n\\nPython has positioned itself as a highly suitable programming language for\\ndata exploration and analysis with its rich ecosystem of libraries such as\\nNumPy, SciPy, pandas, maptplolib, scikit-learn, etc. and interactive\\nvisualization environments such as Jupyter notebooks. The ArcGIS Python API\\nfollows suite in being your library for comprehensive analyses of geospatial\\ndata. With an intuitive design and easy to use syntax, the API opens up access\\nto rich geoprocessing services and big data analysis capabilities of spatial\\ndata.\\n\\nArcGIS API for Python is a Python library for working with maps and geospatial\\ndata. It provides simple and efficient tools for sophisticated vector and\\nraster analysis, geocoding, map making, routing and directions, as well as for\\norganizing and managing a GIS with users, groups and information items. In\\naddition to working with your own data, the library enables access to ready to\\nuse maps and curated geographic data from Esri and other autorotative sources.\\nIt also integrates well with the scientific Python ecosystem and includes rich\\nsupport for Pandas and Jupyter notebook.\\n\\nThis workshop will cover how analysts and data scientists can use the ArcGIS\\nplatform in combination with data science libraries from Python for mapping,\\nvisualization and geospatial data analysis.\\n\\nA proposed outline of the talk is below:\\n\\n  * **Jupyter notebooks for geospatial data science and analysis**\\n  * **Mapping**\\n  * the map widget\\n  * web maps\\n  * 3d maps / scenes\\n  * **Exploratory data analysis**\\n  * Feature and raster layers\\n  * pandas \\n  * spatial dataframe\\n  * **Visualization**\\n  * matplotlib and bokeh charting\\n  * smart mapping, heatmaps\\n  * hotspots, space time cubes\\n  * **Analysis**\\n  * Spatial analysis\\n  * GeoAnalytics (big data analysis)\\n  * Raster analysis\\n  * Integration with data science libraries\\n  * Opencv-python and imagery layers\\n  * **Machine learning with geospatial data**\\n  * Scikit-learn and feature data\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Basic Python / programming knowldge\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://developers.arcgis.com/python/sample-notebooks/\\n\\nhttps://developers.arcgis.com/python/\\n\\nhttps://github.com/Esri/arcgis-python-\\napi/blob/master/talks/uc2017/ArcGIS%20Python%20API%20for%20Analysts%20and%20Data%20Scientists/ArcGIS%20Python%20API%20for%20Analysts%20and%20Data%20Scientists.ipynb\\n\\n\\n\\n#### **Speaker Info:**\\n\\nRohit Singh is the lead developer of ArcGIS API for Python, at Esri, the world\\nleader in GIS.\\n\\nRohit graduated from IIT Kharagpur with a degree in Architecture and has\\nextensive experience and passion in the field of software design and\\ndevelopment. In a rich career spanning over 18 years, Rohit has worked for\\nlarge and small companies, including startups as well as global technology\\nbehemoths such as IBM and TCS. For the past 15 years, he has worked as a lead\\nsoftware architect at Esri, the world leader in GIS, and been instrumental in\\nthe design and development of several industry leading GIS products such as\\nArcGIS Engine, ArcGIS Enterprise and the ArcGIS API for Python. He frequently\\npresents at conferences around the world, showcasing the latest developments\\nin the field of geospatial analysis and technology.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nhttps://github.com/rohitgeo\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/geospatial-data-science-and-analysis-using-arcgis-api-for-python~eZp8b/",
			"speaker": {
				"name": "Rohit Singh",
				"info": "",
				"photo": ""
			}
		},
		"42": {
			"title": "Getting Started with Embedded Python: MicroPython and CircuitPython",
			"description": "\\n\\n#### **Description:**\\n\\nThe **MicroPython** project is an open source implementation of Python 3 that\\nincludes a small subset of the Python standard libraries, and is optimised to\\nrun on microcontrollers with constrained environments like limited ROM, RAM\\nand processing power. It came to life after a successful Kick-starter campaign\\nby Damien George. CircuitPython is a fork of MicroPython further developed by\\nAdafruit Industries(https://www.adafruit.com) which includes great extension\\nto control analog sensors, RGB and neopixel LEDs etc.\\n\\nTraditionally Microcontrollers like AVR, ARM, ESP8266(WiFi SoC) are programmed\\nin Embedded C or Assembly which has a quite overwhelming learning curve,\\nMicroPython makes it easy and allows you to do same with your favourite\\nscripting language Python. Imagine you want to read a sensor or turn on lights\\nfrom a web server, now you don't need to learn register level programming for\\nthat, you can do that with MicroPython, It is also supported on 5$ WiFi SoC,\\nthe ESP8266 which is great for making small IoT devices.\\n\\nMicroPython is packed full of advanced features such as an interactive prompt,\\narbitrary precision integers, closures, list comprehension, generators,\\nexception handling and more. Yet it is compact enough to fit and run within\\njust 256k of code space and 16k of RAM.\\n\\nMicroPython aims to be as compatible with normal Python as possible to allow\\nyou to transfer code with ease from the desktop to a microcontroller or\\nembedded system. You get an interactive prompt (the REPL) to execute commands\\nimmediately, along with the ability to run and import scripts from the built-\\nin filesystem. The REPL has history, tab completion, auto-indent and paste\\nmode for a great user experience.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Basic Python programming language.\\n  * Basic understanding of processors and programming paradigm.\\n  * Basic command line exposure.\\n\\n\\n\\n#### **Content URLs:**\\n\\nMy article on \"Getting Started with MicroPython\" was published in:\\n\\n  * Open Source for you Magazine - Feb 2017 Link: [An Introduction to MicroPython](http://opensourceforu.com/2017/03/an-introduction-to-micropython/)\\n\\n  * Electronics for you Magazine - May 2017\\n\\n[Link to the\\npresentation](https://www.slideshare.net/AyanPahwa1/pyconindia2017micropythonayan)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am working as an Embedded Software Engineer at Mentor Graphics- A Siemens\\nBusiness in Noida facility, working mainly on customised Linux kernel and user\\nland environment for Embedded Automotive Solutions like In-Vehicle-\\nInfotainment(IVI) and Advanced Driver Assistance Systems(ADAS).\\n\\nApart from that I am an IoT, Wearable Electronics and Artificial Intelligent\\nenthusiasts, managing operations in same for an IoT startup(http://sdiot.in).\\nI like to code and make DIY projects for fun or automating things. I am a\\nregular blogger for various communities and blog sites. I do lots of open\\nsource contribution in various projects ranging from Home Automations to Drone\\ntechnologies to Embedded libraries.\\n\\nI am also among few FPV drone racing pilot from India, member of Indian Drone\\nRacing League [IDRL](http://droneracingindia.com). I've organised various\\nworkshops, meet ups and drone air shows in Delhi/NCR on Drone technologies,\\nPython programming language, Linux bash scripting, Github, Contributing in\\nopen source, Microcontrollers etc, in companies, colleges and meet up groups.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [**Website**](https://iayanpahwa.github.io)\\n  * [**Github**](https://www.github.com/iayanpahwa)\\n  * [**Youtube**](https://www.youtube.com/channel/UCgz03WhmWF3otcwXd38bQ9g)\\n  * [**Twitter**](https://www.twitter.com/iAyanPahwa)\\n  * [**Blog on security**](https://www.mentor.com/tannereda/blog/post/securing-iot-devices-2fb40c65-7b7e-4f73-a4c2-89d45b843bfc)\\n  * [**MicroPython article in open source for you magazine- Feb 2017 edition**](http://opensourceforu.com/2017/03/an-introduction-to-micropython/)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/getting-started-with-embedded-python-micropython-and-circuitpython~dN7me/",
			"speaker": {
				"name": "Ayan Pahwa",
				"info": "",
				"photo": ""
			}
		},
		"43": {
			"title": "Spinning local DNS server sourcing responses over HTTPS to combat Man-in-the-middle attack",
			"description": "\\n\\n#### **Description:**\\n\\n  * It is close to impossible to use any port other than Port 53 to fetch DNS seamlessly across macOS, Windows, Android or iOS.\\n  * The **DNS protocol does not have any mechanism to avoid being tampered**.\\n  * This makes it very easy for any ISP, intermediary party or hacker to give wrong DNS values. We will be able to tell apart false IPs on HTTPS, but we are totally helpless while getting the correct IPs or safeguarding the services that do not implement SSL.\\n  * The solution lies by querying the DNS inside our own network, where we are sure of not being [MitM](https://en.wikipedia.org/wiki/Man-in-the-middle_attack)'d.\\n\\nTo approach the above, we will be running a DNS Server on our system, and\\nsourcing the replies not by the conventional way of upstreaming it via port\\n53, but by fetching the DNS information via HTTPS using Google's DNS APIs.\\n\\nIn the attached repo, I have implemented a simple DNS Server written using\\nTwisted. It is based on a Twisted DNSServerFactory, using a custom DNS\\nresolver, which is **fetching the DNS by\\nquerying[dns.google.com](https://dns.google.com) over HTTPS** , fetching the\\nJSON response, and further translating it to a DNS response to be used\\nlocally.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Purpose of DNS\\n  * Familiarity with [`dig`](ftp://ftp.isc.org/isc/bind9/cur/9.11/doc/arm/man.dig.html)\\n  * How basic [Man in the Middle](https://en.wikipedia.org/wiki/Man-in-the-middle_attack) attack works, and how cryptographic systems beat it\\n  * What is [DNSSEC](https://en.wikipedia.org/wiki/Domain_Name_System_Security_Extensions)\\n\\n\\n\\n#### **Content URLs:**\\n\\n[github.com/arn7av/gDNS](https://github.com/arn7av/gDNS)\\n\\n[Presentation](http://slides.com/arn7av/gdns)\\n\\n[pip](https://pypi.org/project/gDNS/)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nArnav is currently working as a Developer at [hedgehog\\nlab](https://hedgehoglab.com/), Hyderabad. He completed his bachelors from VIT\\nUniversity, Vellore. Having spent half a decade behind the computer screen, he\\noften gives valuable insight into Web Architecture, Network Infrastructure &\\nSecurity and Hardware. When he is unable to find the most elegant and\\npractical way to approach a solution, he is often found reading and outputting\\nchunks of python code. He also takes out time and enjoys mentoring peers on\\ngood coding etiquettes. Rest of the time he is deeply devoted leading his DotA\\nteam.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n[arnav.at](https://arnav.at/)\\n\\n[linkedin.com/in/arnav7/](https://www.linkedin.com/in/arnav7/)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/spinning-local-dns-server-sourcing-responses-over-https-to-combat-man-in-the-middle-attack~eVnoe/",
			"speaker": {
				"name": " arnAV",
				"info": "",
				"photo": ""
			}
		},
		"44": {
			"title": "Scientific computing using Cython: Best of both worlds!",
			"description": "\\n\\n#### **Description:**\\n\\nCython is not only an excellent and widely used tool to speed up computational\\nPython code, it\u2019s also a very smart way to talk to native code and libraries.\\nThe Cython compiler translates Python code to C or C++ code, and supports\\nstatic type annotations to allow direct use of C/C++ data types and functions.\\nYou get the best of both worlds while working with Cython: Python like syntax\\nwith blazing fast C speed.\\n\\nThis talk/tutorial by a Python/Cython developer introduces Cython programming\\nlanguage and leads the participants all the way from their first Python\\nextension to an efficient integration with native C. Topics covered will be:\\n1. Using the Cython compiler to build a native extension module 2. Cython\\ndevelopment from Jupyter notebook 3. Mixing Python with static C types in the\\nCython language 4. Calling into native code from Cython code (Brief\\nintroduction) 5. Wrap up: A brief case study Cyvlfeat: A Cython/Python wrapper\\nfor Computer Vision library, VLFeat.\\n\\nParticipants are expected to have a good understanding of the Python language,\\nsome basic knowledge about C or C++. No deep C programming knowledge is\\nrequired, nor is any prior knowledge needed about writing extension modules\\nfor the CPython runtime.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nParticipants should be familiar with Python syntax and C syntax (Optional).\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://github.com/simmimourya1/europython17\\n\\n\\n\\n#### **Speaker Info:**\\n\\nSimmi Mourya is on a mission to promote the Python programming language to\\nfacilitate the growth of a diverse community of Python Ninjas. She is a deep\\nlearning engineer at Predible Health. Her interest lies in Deep Learning and\\nArtificial Intelligence. She is about to finish Udacity's Artificial\\nIntelligence Nano-degree. She has a good amount of experience in Cython\\nprogramming language because of her contributions to Cyvlfeat, a Cython/Python\\nwrapper for famous Computer Vision library named VLFeat. Find it here:\\nhttps://github.com/menpo/cyvlfeat She has a lot of speaking experience. She's\\nan active speaker at Women Tech Makers Delhi, India. Previously, she has\\npresented at Europython 2017, Fossasia Open Tech Summit 2017, Singapore. She\\nis a past Google Summer of Code scholar. She has also provided mentoring\\nsupport for Google Code-In 2016. You can find her stargazing almost every\\nnight! She loves photography and singing. She makes the best pasta!\\n\\n\\n\\n#### **Speaker Links:**\\n\\nhttps://github.com/simmimourya1 https://gsoc2016.wordpress.com\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/scientific-computing-using-cython-best-of-both-worlds~aO5Qd/",
			"speaker": {
				"name": "Simmi Mourya",
				"info": "",
				"photo": ""
			}
		},
		"45": {
			"title": "How import works in Python",
			"description": "\\n\\n#### **Description:**\\n\\n**Import machinery** has been revamped and has been re-written in Python3. Not\\nmany of the developers are aware of the internal mechanics of how the import\\nsystem works and how this can be leveraged for some specific use cases\\n\\nThis talk will introduce the audience to:\\n\\n  * Evolution of import system in python\\n  * What happens under the hoods when a module/package is imported into Python namespace\\n  * Various hooks available that can be leveraged for customization\\n  * Some of the usecases where this can be leveraged\\n\\nAfter the talk, audience will get a clear idea of how import system is\\nimplemented in Python3 and will be able to leverage the hooks available for\\nany future use cases\\n\\n\\n\\n#### **Prerequisites:**\\n\\nKnowledge of python programming, basic understanding of Python modules and\\nPackages, knowledge of python standard library modules like sys, os, etc\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://github.com/sdonapar/how_import_works\\n\\nhttps://github.com/sdonapar/how_import_works/blob/master/how_import_works.pdf\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am a mechanical engineering graduate with 25+ years of experience in\\nmanufacturing and financial services domains, I have started my career as\\ndesign engineer in hydraulic turbine manufacturing company. After spending 5\\nyears, I have stated my IT journey at Aspect Development/i2 Technology. I have\\nworked primarily on data scrubbing, modelling, analysis and data migration\\nprojects for supply chain management. I then joined technology services side\\nof Fidelity, financial services company. I have been using python for last 5\\nyears for automation, data analysis, web development, etc. I am very excited\\nabout the endless opportunities that arise in day today work and application\\nof python for solving/automating the same. I am very passionate about teaching\\npython to engineering students thru pythonexpress program. I conduct regular\\ntraining sessions for data analys ( numpy, pandas and matplotlib).\\n\\n\\n\\n#### **Speaker Links:**\\n\\ngithub link - https://github.com/sdonapar\\n\\nlinkedin profile - https://www.linkedin.com/in/sasidonaparthi\\n\\ntwitter handle - **@sdonapar**\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/how-import-works-in-python~dypzb/",
			"speaker": {
				"name": "Sasidhar Donaparthi",
				"info": "",
				"photo": ""
			}
		},
		"46": {
			"title": "Using Python and microservices to fuel WebPush at Mozilla",
			"description": "\\n\\n#### **Description:**\\n\\nIn this talk, I\u2019ll be talking about how WebPush works, what are the key\\ncomponents involved and their roles in depth. Following this, I will be\\nexplaining how to build a webpush microservice written in Python for your\\napplication server.\\n\\nFollowing is the break up of my talk:\\n\\nWhat is Web Push?\\n\\n  * A brief about what the webpush technology is and how it works. \\n  * What are service workers and their role in webpush.\\n  * What are push servers and their role in webpush.\\n  * How to subscribe to push notifications\\n\\nHow to build a webpush microservice using Python?\\n\\n  * What are the various components?\\n  * How to handle authentication for requests?\\n  * What are channels and how to implement them?\\n  * How to implement subscription to a channel?\\n  * How to implement publishing to a channel?\\n\\n\\n\\n#### **Prerequisites:**\\n\\nHTTP Verbs\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://docs.google.com/presentation/d/161Om8lLaXJYF5nqrYkoP8Zzm26Kxh8LpXAZ76LoYDSc/edit?usp=sharing\\n\\n\\n\\n#### **Speaker Info:**\\n\\nMansimar was a software developer intern at Mozilla and as part of her\\ninternship, developed a PubSub channels based push microservice. She has\\nspoken at [FOSDEM 2017](https://www.youtube.com/watch?v=Ld4PFVlbCPk&t=9s) and\\n[EuroPython 2017](https://ep2017.europython.eu/en/) about the webpush\\ntechnology and has written a series of\\n[articles](https://medium.com/@mansimarkaur.mks)) about her work and webpush\\ntechnology. She has worked on Brew as part of her Google Summer of Code with\\nHomebrew. Previously, she worked on HackerRank's autocompletion service as an\\nintern. Being an ardent open source enthusiast, she has contributed to Kinto -\\na minimalist JSON storage service, Brackets - a code editor by Adobe and also\\nhas a string of self-projects that she's proudly maintaining.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n[FOSDEM 2017](https://archive.fosdem.org/2017/schedule/event/python_kinto/)\\n\\n[Europython 2017](https://ep2017.europython.eu/conference/talks/using-python-\\nand-microservices-to-fuel-webpush)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/using-python-and-microservices-to-fuel-webpush-at-mozilla~b6KNd/",
			"speaker": {
				"name": "Mansimar Kaur",
				"info": "",
				"photo": ""
			}
		},
		"47": {
			"title": "Panel Discussion on Women in Open Source",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"48": {
			"title": "Visualising the world of competitive programming with Python",
			"description": "\\n\\n#### **Description:**\\n\\nCompetitive programming has grown exponentially in the last decade. Millions\\nof students, teachers, professionals solve problems including complex\\noptimisations every minute. With the influx of programming languages,\\ndevelopers have a wide range of tools to choose from and use them to solve\\ncompetitive challenges. Some of the popular platforms include Codeforces,\\nCodechef, Hackerrank, Hackerearth, Topcoder etc.\\n\\nIn this talk we are going to use the dataset of codes scraped from Codeforces\\nfrom a variety of challenges. These include programs written by top rated\\ncoders across the world to the newbies. The platform allows you to code in 26\\ndifferent languages which obviously include popular programming languages like\\nC, C++, Java, Javascript, PHP, Python etc. There are a very wide range of\\nchallenges in competitive programming like Sorting, Binary Search, Trees,\\nGraphs, Dynamic Programming to name a few. The talk will cover the\\nvisualization of the dataset among broad classifications of how each\\nprogramming language performs in these classifications. How efficient are\\nprogramming languages across classifications in terms of time and memory and\\nseveral others?The talk would also specifically cover the ease of using Python\\nto solve different classes of challenges in competitive programming and the\\nusage of Python over time.\\n\\nMajor takeaways :\\n\\n  1. ABC of web scraping and best practices. \\n  2. Optimizing web scraping to scale. \\n  3. No-SQL databases for storing unstructured data\\n  4. How does Python as a language fare in competitive programming in terms of efficiency and popularity?\\n  5. Can I pursue competitive programming using Python ONLY?\\n  6. An analysis of popular programming languages used for solving challenges.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nFamiliarity with Python. Familiarity with web scraping is a huge plus.\\n\\n\\n\\n#### **Content URLs:**\\n\\nProposal Draft : https://www.slideshare.net/AnujMenta/visualising-the-world-\\nof-competitive-programming-with-python-codeforces\\n\\n\\n\\n#### **Speaker Info:**\\n\\nI am an IIT Kharagpur graduate(2017) who spent over 4 years coding in Python.\\nWorked with all styles of python from website development using Django and\\nFlask to scientific computing using numpy and scikit-learn to web-scraping\\nusing Selenium. It's been a wonderful journey all along and I'm now looking\\nforward to bring as many people on board as I can to experience what I've\\nexperienced.\\n\\nI am also the founder of Papercop, an examination preparation portal for the\\nstudents of IIT Kharagpur which has about 70k+ hits. I am a very passionate\\nspeedcuber( Can solve the rubiks cube in about 10s odd). Won plenty of medals\\nin speedcubing competitions across the country. I now work as an analyst with\\nAmerican Express.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nGithub : https://github.com/anujmenta\\n\\nLinkedIn : https://in.linkedin.com/in/anuj-menta-314b5969\\n\\nWorld Cube Association Profile :\\nhttps://www.worldcubeassociation.org/persons/2013MENT01\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/visualising-the-world-of-competitive-programming-with-python~epBmb/",
			"speaker": {
				"name": "Anuj Menta",
				"info": "",
				"photo": ""
			}
		},
		"49": {
			"title": "How is __metaclass__ used in real life.",
			"description": "\\n\\n#### **Description:**\\n\\nClass objects in python are themselves instances of the `type` class. Usage of\\nthe `metaclass` allows you to modify the process of creating a class object.\\nPractical use-cases use `metaclass` attribute to add, delete, rename, or\\nsubstitute methods and attributes in the class that is initiated.\\n\\n**Content:**\\n\\n**Theory**\\n\\n  1. Class objects are instances of `type` class\\n  2. How to override the `type` class\\n  3. Introduction to the `__prepare__` method\\n\\n**Examples**\\n\\n  1. How to create singleton classes in Python\\n  2. Using `metaclass` to introduce methods in a class without inheritance \\n  3. How `metaclass` is used in Django REST Framework Serializers.\\n  4. How Django uses `metaclass` to maintain backward compatibility\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  1. Intermediate familiarity object oriented programming concepts and how inheritance works in Python\\n  2. Basic understanding of serializers (Not compulsory).\\n\\n\\n\\n#### **Content URLs:**\\n\\n[**My content**](https://github.com/vimarshc/metaclass-talk)\\n\\n**Other links**\\n\\n  1. [invoking metaclass](https://www.python.org/dev/peps/pep-3115/#invoking-the-metaclass)\\n  2. [metaclass docs](https://docs.python.org/3/reference/datamodel.html#customizing-class-creation)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nVimarsh Chaturvedi is currently working at [Hedgehog\\nlabs](https://hedgehoglab.com/) as Developer. Graduated from Delhi\\nTechnological University in 2016. Lover of Python and small time contributor\\nto Django REST Framework. In his spare time he likes to get into the nuts and\\nbolts of Django and Django REST Framework. Likes to override DRF\\nfunctionalities and write `mixins` on steroids for fun. Firm believer of if\\nyou have to write the same code twice there is a more elegant way to do it.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n[Github](https://github.com/vimarshc)\\n\\n[Linkedin](https://www.linkedin.com/in/vimarshc/)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/how-is-__metaclass__-used-in-real-life~epByb/",
			"speaker": {
				"name": "Vimarsh Chaturvedi",
				"info": "",
				"photo": ""
			}
		},
		"50": {
			"title": "Django on Steroids -- Building Applications at Web Scale",
			"description": "\\n\\n#### **Description:**\\n\\nDjango is an excellent web-application framework to build scalable, extensible\\nand high-performance web applications that can serve hundreds of thousands of\\nrequests per second -- while keeping the development cycle optimal and\\nmaintaining the sanity of developer mind-space. The success of the framework\\ncan be attributed to the well-thought out design patterns and opinionated\\ndecisions the framework makes that walks the thin line between having all\\nbatteries included and giving the developer tremendous room to grow out of the\\nbox.\\n\\nThis talk summarizes my learning from using Django as the core application\\nengine in multiple production applications for the past two years at DoSelect\\nto serve tens of millions of requests everyday, while maintaining stringent\\navailability SLAs and extremely low response times. The content of the talk\\noutlines the best practices and gotchas in using Django meant for web scale --\\nright from designing the project layouts to writing different components of\\nyour app, and finally breaking out of Django and using the best tools to\\nsupport performance and reliability of your application.\\n\\nThe talk would be structured around the following focus areas:\\n\\n  1. Structuring your Django project for extensibility and performance\\n  2. Designing your request-response workflow for optimal throughput\\n  3. How to write Django queries that don't kill your application\\n  4. Designing your caching workflow\\n  5. Using components around your Django app optimally -- Gunicorn, NGINX, PostgreSQL, etc.\\n\\nThe talk will include real-world code examples while illustrating the points\\nabove \u2013 explaining what I faced in production, and how I solved it (and then\\nrealized that\u2019s what I should have done in the first place). This talk builds\\non top of a talk given by me at [PyCon Pune\\n2017](https://pyconpune.talkfunnel.com/2017/63-django-on-steroids-lessons-\\nfrom-scale) \\-- the content has evolved as I have while continuing on quest to\\nuse Django better in production.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nThe talk is intended for people who have a basic knowledge of Python / Django,\\nknow how web applications work in general. Key take-aways would be things you\\ncan directly drop into your production Django application for better\\nperformance.\\n\\n\\n\\n#### **Content URLs:**\\n\\n  1. [Talk at PyCon Pune 2017](https://www.youtube.com/watch?v=E5JQlHLimTA)\\n  2. [Talk at PyCon India 2013](https://www.youtube.com/watch?v=ZfnWRe0J4UE)\\n  3. [Django on Steroids -- Slides](https://sanketsaurav.github.io/django-on-steroids/)\\n  4. [Lessons from Scale: Django](https://sanketsaurav.com/lessons-from-scale-django-124f7b16ae0c)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nSanket ([@sanketsaurav](https://twitter.com/sanketsaurav)) is co-founder and\\nChief of Geeks at [DoSelect](http://doselect.com). He\u2019s 50% developer and 50%\\ndesigner. He\u2019s been dabbling with computers since the age of 10, and had\\nstarted his first venture at 18. He loves the Web and likes building cool\\nstuff that matter. His languages of choice are Python, Go and JavaScript, and\\nhe\u2019s been building production apps using these for the past two years. He\u2019s\\nalso spoken at more than 50 events and hackathons across the country on open\\nsource technologies including Python, HTML5 and web applications in general.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  1. [GitHub](http://github.com/sanketsaurav)\\n  2. [Website](http://sanketsaurav.com)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/django-on-steroids-building-applications-at-web-scale~ejLBb/",
			"speaker": {
				"name": "Sanket Saurav",
				"info": "",
				"photo": ""
			}
		},
		"51": {
			"title": "OLMONK : Data validation package",
			"description": "\\n\\n#### **Description:**\\n\\nThe cycle of data analysis involves many stages from data gathering to data\\nvisualization, with data filtering being one of the limiting steps. The need\\nfor data filtering will arise from problems in the way the data is entered and\\nstored. Mistakes as simple as setting a numeric column to character data type,\\nor passing null values to required parameters can result in crashes or\\nundefined behavior. OLMONK helps one avoid them, and enables smooth data\\nanalysis and visualization.\\n\\nThe package can be used as a validation layer before any kind of data analysis\\nsoftware. While building a software, the developer can import OLMONK and can\\ndefine constraints depending on the required input format. The package then\\nlogs appropriate warnings and errors, along with data location (i.e. row and\\ncolumn info), in a file, and notifies the user of the same. While most of the\\nstandard inconsistencies can be rectified by OLMONK, some cases may require\\nhuman intervention and for them the package raises errors.\\n\\nIt allows the user to ensure the correctness of data, before feeding the\\nanalysis tool with potentially incompatible data. One can validate different\\nkinds of data with tailor-made checks. It can currently process .csv, .txt,\\n.xlsx, .bed format files.\\n\\nOLMONK enables the user to:\\n\\n  1. Validate data with single config file \\n  2. Add external validation functions\\n  3. Generate report In different formats\\n  4. Use inbuilt data validation checks such as a check for subset, superset or duplicates\\n\\nThe code follows PEP8 and PEP256 guidelines throughout, and has been tested\\nwith >90% test coverage.\\n\\nThe talk will be focused on how to use the package for validating demo files\\nand discuss scope of the package in various industries.\\n\\n\\n\\n#### **Prerequisites:**\\n\\nPython\\n\\n\\n\\n#### **Content URLs:**\\n\\nhttps://drive.google.com/drive/folders/0B1x1H20bti0benpSS0l5eDQ4cWM?usp=sharing\\n\\n\\n\\n#### **Speaker Info:**\\n\\nAnkur is a developer with over 4 years of experience in domain varying across\\nEmbedded Systems, Robotics, and Data Science. He currently works as a\\ndeveloper at Elucidata Corporation, where he builds models that help\\nscientists process biological data. He holds Bachelor's degree from Indian\\nInstitute of Information Technology, Jabalpur.\\n\\n\\n\\n#### **Speaker Links:**\\n\\nLinkedIn Profile: https://linkedin.com/ankur-agrawal-9a280752/\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/olmonk-data-validation-package~aO6Ee/",
			"speaker": {
				"name": "ankur09011",
				"info": "",
				"photo": ""
			}
		},
		"52": {
			"title": "PyBeacon: Eddystone Protocol implementation in Python",
			"description": "\\n\\n#### **Description:**\\n\\nEddystone is a protocol specification, an open beacon format from Google, that\\ndefines a Bluetooth low energy (BLE) message format for proximity beacon\\nmessages. It describes several different frame types that may be used\\nindividually or in combinations to create beacons that can be used for a\\nvariety of applications. PyBeacon is an Eddystone implementation in Python for\\nLinux systems. Using this, Linux systems can be used as a beacon or a beacon\\nscanner.\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Should have a basic understanding of Python.\\n\\n\\n\\n#### **Content URLs:**\\n\\n  * [Drafted Presentation](http://slides.com/prabhanshuattri/pybeacon-eddystone-protocol-implementation-in-python)\\n  * [PyBeacon](https://github.com/nirmankarta/PyBeacon)\\n  * [Eddystone](https://github.com/google/eddystone/)\\n  * [PyBeacon on PyPi](https://pypi.python.org/pypi/PyBeacon)\\n  * [Eddystone URL Protocol](https://github.com/google/eddystone/tree/master/eddystone-url)\\n  * [Eddystone UID Protocol](https://github.com/google/eddystone/tree/master/eddystone-uid)\\n  * [PyBeacon in Eddystone Repo](https://github.com/google/eddystone/tree/master/eddystone-url/implementations/PyBeacon)\\n\\n\\n\\n#### **Speaker Info:**\\n\\nPrabhanshu Attri is a RGSoC Mentor, an open source enthusiast, IEEE CS Richard\\nE Merwin Scholar and Former Summer Research Intern at Indian Institute of\\nTechnology Guwahati. He has also worked as a Software Development Engineer at\\nZomato.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [Website](http://prabhanshu.com)\\n  * [GitHub](http://prabhanshu.com/github-repo)\\n  * [LinkedIn](http://prabhanshu.com/linkedin)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/pybeacon-eddystone-protocol-implementation-in-python~eXpVe/",
			"speaker": {
				"name": "Prabhanshu Attri",
				"info": "",
				"photo": ""
			}
		},
		"53": {
			"title": "Clean Architecture Applications in Python",
			"description": "\\n\\n#### **Description:**\\n\\nClean Architecture helps you build applications that are:\\n\\n  * Independent of Frameworks\\n  * Testable\\n  * Independent of UI\\n  * Independent of Database\\n  * Independent of any external agency\\n\\nThis talk will be an introduction to Clean Architecture principles and system\\ndesign in Python. We will choose a sample application and walk through a\\nsimple usecase of creating clean code.\\n\\nWhat you will gain from this talk:\\n\\n  1. Grow your application with confidence\\n  2. Build applications to be independent of infrastructure like Web Frameworks, Database etc.\\n  3. Avoid mixing of business logic across different layers of your application\\n  4. Test close to 100% of your core business logic\\n  5. Keep your tests fast and independent of infrastructure (DB, Web Layer etc.)\\n\\n\\n\\n#### **Prerequisites:**\\n\\n  * Python Programming Fundamentals\\n  * Basic knowledge of Design concepts, like Dependency Injection, Single responsibility principle etc.\\n  * Experience with building web applications\\n\\n\\n\\n#### **Content URLs:**\\n\\nDraft WIP Slides: <https://www.slideshare.net/secret/65KBnY4zwSpVjA>\\n\\n\\n\\n#### **Speaker Info:**\\n\\nSubhash has 14+ years of software development experience in a variety of\\ndomains, technical roles, software languages and frameworks. His tryst with\\nPython began recently though, about an year ago. Currently, he runs a\\nConsultancy startup aimed at providing Platform Design, Architecture and\\nDevelopment services.\\n\\nHis interests are large scale web platform development, system\\ndesign/architecture and DevOps friendly processes.\\n\\n\\n\\n#### **Speaker Links:**\\n\\n  * [Github](https://github.com/subhashb)\\n  * [Twitter](https://twitter.com/subhashbhushan)\\n\\n",
			"type": "talk",
			"cfp": "https://in.pycon.org/cfp/2017/proposals/clean-architecture-applications-in-python~bqDka/",
			"speaker": {
				"name": "Subhash Bhushan",
				"info": "",
				"photo": ""
			}
		},
		"54": {
			"title": "Sponsored Workshop/Talks 4",
			"description": "",
			"type": "talk",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"55": {
			"title": "Closing Ceremony",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		},
		"56": {
			"title": "DevOps @ Microsoft with Python (Sponsored Talk)",
			"description": "",
			"type": "default",
			"speaker": {
				"name": "Microsoft",
				"info": "",
				"photo": ""
			},
			"cfp": ""
		}
	}]
}